<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>虚拟机搭建Hadoop集群 | 技术匝记簿</title><meta name="author" content="残魁斜罡"><meta name="copyright" content="残魁斜罡"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="虚拟机搭建Hadoop集群1. 创建虚拟机下载VirtualBox或其他虚拟机软件并安装. 进入管理菜单-&gt;全局设置-&gt;网络-&gt;添加新NAT网络, 勾选启用网络并开启DHCP,确认即可.  随后点击新建虚拟机, 将名称改为cluster1, 虚拟机类型选择Linux, Red Hat(64位),  将内存大小改为1536MB,点击下一步  选择现在创建虚拟硬盘(VHD, 动态分配">
<meta property="og:type" content="article">
<meta property="og:title" content="虚拟机搭建Hadoop集群">
<meta property="og:url" content="https://www.ckxgzxa.top/HadoopContructionOnVM.html">
<meta property="og:site_name" content="技术匝记簿">
<meta property="og:description" content="虚拟机搭建Hadoop集群1. 创建虚拟机下载VirtualBox或其他虚拟机软件并安装. 进入管理菜单-&gt;全局设置-&gt;网络-&gt;添加新NAT网络, 勾选启用网络并开启DHCP,确认即可.  随后点击新建虚拟机, 将名称改为cluster1, 虚拟机类型选择Linux, Red Hat(64位),  将内存大小改为1536MB,点击下一步  选择现在创建虚拟硬盘(VHD, 动态分配">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/blogpictures/202312060211044.png">
<meta property="article:published_time" content="2022-03-07T09:12:03.000Z">
<meta property="article:modified_time" content="2022-04-14T12:15:50.678Z">
<meta property="article:author" content="残魁斜罡">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/blogpictures/202312060211044.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://www.ckxgzxa.top/HadoopContructionOnVM.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":50},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 残魁斜罡","link":"链接: ","source":"来源: 技术匝记簿","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '虚拟机搭建Hadoop集群',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-04-14 20:15:50'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="技术匝记簿" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">68</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">20</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://zxastaticpages.oss-cn-beijing.aliyuncs.com/blogpictures/202312060211044.png')"><nav id="nav"><span id="blog-info"><a href="/" title="技术匝记簿"><img class="site-icon" src="/img/favicon.png"/><span class="site-name">技术匝记簿</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">虚拟机搭建Hadoop集群</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-03-07T09:12:03.000Z" title="发表于 2022-03-07 17:12:03">2022-03-07</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-04-14T12:15:50.678Z" title="更新于 2022-04-14 20:15:50">2022-04-14</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="虚拟机搭建Hadoop集群"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="虚拟机搭建Hadoop集群"><a href="#虚拟机搭建Hadoop集群" class="headerlink" title="虚拟机搭建Hadoop集群"></a>虚拟机搭建Hadoop集群</h1><h2 id="1-创建虚拟机"><a href="#1-创建虚拟机" class="headerlink" title="1. 创建虚拟机"></a>1. 创建虚拟机</h2><p>下载VirtualBox或其他虚拟机软件并安装.</p>
<p>进入管理菜单-&gt;全局设置-&gt;网络-&gt;添加新NAT网络, 勾选启用网络并开启DHCP,确认即可.</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307172344864.png"></p>
<p>随后点击新建虚拟机, 将名称改为cluster1, 虚拟机类型选择Linux, Red Hat(64位),</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307172741873.png"></p>
<p>将内存大小改为1536MB,点击下一步</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307172827900.png"></p>
<p>选择现在创建虚拟硬盘(VHD, 动态分配, 8G), 点击创建即可成功创建虚拟机:</p>
<p>如下图所示,</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307173039991.png"></p>
<p>进入刚刚新建的虚拟机设置, 在网卡1处连接方式选择NAT网络, 在网卡2处勾选启用网络连接,连接方式设为: 仅主机(Host-Only)网络,点击OK即可,网络信息如下所示,</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307173502018.png"></p>
<p>然后选择存储设置, 加载CentOS7系统镜像到光驱</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307173709989.png"></p>
<p>确认之后将虚拟机启动,</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307173833389.png"></p>
<p>单击界面,让Virtual Box捕获鼠标(注:右Ctrl键可以接触捕获), 上移光标至Install CentOS 7处按回车键进行系统安装,</p>
<p>随后单击Continue</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307174203851.png"></p>
<p>将时区更改为: :earth_asia: Asia, Shanghai</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307174519139.png"></p>
<p>磁盘分区默认即可,</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307175112388.png"></p>
<p>随后设置用户名和密码, 如果密码不符合安全要求, 会需要点击两次以确认,耐心等待系统安装完成,然后点击重启按钮, 系统即安装完成</p>
<p>另外创建两台配置一样的虚拟机, 用户名分别为 cluster2 和 cluster3.</p>
<h2 id="2-准备工作"><a href="#2-准备工作" class="headerlink" title="2. 准备工作"></a>2. 准备工作</h2><h3 id="2-1-关闭防火墙和-Selinux"><a href="#2-1-关闭防火墙和-Selinux" class="headerlink" title="2.1 关闭防火墙和 Selinux"></a>2.1 关闭防火墙和 Selinux</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 关闭防火墙并阻止服务开机启动</span><br><span class="line"><span class="comment"># systemctl stop firewalld.service</span></span><br><span class="line"><span class="comment"># systemctl disable firewalld.service</span></span><br></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307181250561.png"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// 编辑Selinux配置文件关闭Selinux</span><br><span class="line"><span class="comment"># vi /etc/selinux/config</span></span><br><span class="line">// 将SELINUX设为disabled</span><br><span class="line">// 重启</span><br><span class="line"><span class="comment"># reboot</span></span><br><span class="line">// 用root用户查看Selinux状态</span><br><span class="line"><span class="comment"># getenforce</span></span><br></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307181417466.png"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307181459557.png"></p>
<p>另两台虚拟机进行同样的操作.</p>
<h3 id="2-2-检查网卡是否开机自启"><a href="#2-2-检查网卡是否开机自启" class="headerlink" title="2.2 检查网卡是否开机自启"></a>2.2 检查网卡是否开机自启</h3><p>使用<code>ip addr</code>命令查看网卡名称,</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220308010929988.png"></p>
<p>可见两张网卡均未启用,</p>
<p>接下来编辑第一张网卡的配置文件, 修改如下文件<code>/etc/sysconfig/network-scripts/ifcfg-enp0s3</code>,将其中的ONBOOT项修改为yes,使网卡能够开机自启,</p>
<p>随后编辑第二章网卡的配置文件<code>etc/sysconfig/network-scripts/ifcfg-enp0s8</code>, 将BOOTPROTO设置为none, ONBOOT同样改为yes,并新增如下项:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">IPADDR=192.168.56.121  # cluster2为192.168.56.122, cluster3为192.168.56.123</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line">NETWORK=192.168.56.0</span><br></pre></td></tr></table></figure>

<p>保存之后, 重启网络服务发现配置成功</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220308011832168.png"></p>
<p>将另外两台机器也配置完成,进入下一步,</p>
<p>将网络配置成功之后我们就可以使用SSH工具连接虚拟机了,在这里我使用Finalshell工具进行连接:</p>
<p>添加如下所示的三个连接就可以连上虚拟机了:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220308012637088.png"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220308012706054.png"></p>
<p>对于文件传输功能, Finalshell有集成功能可以方便的拖拽文件进行上传和下载操作.</p>
<h3 id="2-3-安装软件"><a href="#2-3-安装软件" class="headerlink" title="2.3 安装软件"></a>2.3 安装软件</h3><p>每台机器上都要安装,</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install perl*  ntpdate  libaio  screen -y</span><br></pre></td></tr></table></figure>

<h3 id="2-4-修改hosts"><a href="#2-4-修改hosts" class="headerlink" title="2.4 修改hosts"></a>2.4 修改hosts</h3><p>将每台机器的ip写入每台机器的hosts文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">10.0.2.8 cluster1</span><br><span class="line">10.0.2.4 cluster2</span><br><span class="line">10.0.2.9 cluster3</span><br></pre></td></tr></table></figure>

<p>修改之后测试网络连通性, 在cluster1上 ping 另两台机器:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220308183616945.png"></p>
<p>可见hosts文件生效.</p>
<h3 id="2-5-新建用于维护集群的hadoop用户"><a href="#2-5-新建用于维护集群的hadoop用户" class="headerlink" title="2.5 新建用于维护集群的hadoop用户"></a>2.5 新建用于维护集群的hadoop用户</h3><p>在每台机器上用root用户执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建hadoop组</span></span><br><span class="line">groupadd hadoop</span><br><span class="line"><span class="comment"># 新建hadoop用户</span></span><br><span class="line">useradd -s /bin/bash -g hadoop -d /home/hadoop -m hadoop</span><br><span class="line"><span class="comment"># 修改 hadoop 这个用户的密码</span></span><br><span class="line">passwd hadoop</span><br></pre></td></tr></table></figure>

<h3 id="2-6-生成SSH密钥并分发"><a href="#2-6-生成SSH密钥并分发" class="headerlink" title="2.6 生成SSH密钥并分发"></a>2.6 生成SSH密钥并分发</h3><p>首先在cluster1上切换到<strong>hadoop用户</strong>, 然后执行如下命令生成密钥:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>

<p>随后分发密钥,</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id cluster1</span><br><span class="line">ssh-copy-id cluster2</span><br><span class="line">ssh-copy-id cluster3</span><br></pre></td></tr></table></figure>

<p>密钥分发完毕, 使用cluster1与cluster2和cluster3建立连接均能成功,说明密钥分发无误.</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220308231119122.png"></p>
<h3 id="2-7-安装NTP服务"><a href="#2-7-安装NTP服务" class="headerlink" title="2.7 安装NTP服务"></a>2.7 安装NTP服务</h3><p>在三台机器上安装ntpdate</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install ntpdate</span><br></pre></td></tr></table></figure>

<p>在cluster1上执行yum安装命令安装ntp并将<code>/etc/ntp.conf</code>文件的下列四行注释掉,</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">server0.centos.pool.ntp.org iburst</span><br><span class="line">server1.centos.pool.ntp.org iburst </span><br><span class="line">server2.centos.pool.ntp.org iburst </span><br><span class="line">server3.centos.pool.ntp.org iburst</span><br></pre></td></tr></table></figure>

<p>在文件末加入如下内容:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">restrict default ignore</span><br><span class="line">restrict 10.0.2.0 mask 255.255.255.0 nomodify notrap</span><br><span class="line">server 127.127.1.0</span><br></pre></td></tr></table></figure>

<p>重启ntp服务并设置ntp 服务器开机自启</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">service ntpd restart</span><br><span class="line">chkconfig ntpd on</span><br></pre></td></tr></table></figure>

<p>接下来对cluster2和cluster3这两个客户端进行配置:</p>
<p>设定每天0:00向服务器同步时间并写入日志:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># crontab -e</span></span><br></pre></td></tr></table></figure>

<p>输入以下内容后保存并退出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 0 * * * /usr/sbin/ntpdate cluster1&gt;&gt; /root/ntpd.log</span><br></pre></td></tr></table></figure>

<p>之后在两台客户机上使用<code>ntpdate cluster1</code>同步时间.</p>
<h2 id="3-安装MySQL"><a href="#3-安装MySQL" class="headerlink" title="3. 安装MySQL"></a><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309011624607.png">3. 安装MySQL</h2><h3 id="3-1-安装"><a href="#3-1-安装" class="headerlink" title="3.1 安装"></a>3.1 安装</h3><p>只需要在cluster2上安装一个MySQL即可</p>
<p>登录root用户以执行以下命令:</p>
<p>若安装过MySQL先移除原有MySQL:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum remove mysql mysql-server mnysql-libs compat-mysql51</span><br><span class="line"><span class="built_in">rm</span> -rf /var/lib/mysql</span><br><span class="line"><span class="built_in">rm</span> -rf /etc/my.cnf</span><br></pre></td></tr></table></figure>

<p>将mysql-5.6.37-linux-glibc2.12-x86_64.tar.gz上传至cluster2,随后将其解压到/usr/local/目录下,并将解压后的文件目录名改为mysql</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf mysql-5.6.37-linux-glibc2.12-x86_64.tar.gz</span><br><span class="line"><span class="built_in">mv</span> mysql-5.6.37-linux-glibc2.12-x86_64 mysql</span><br></pre></td></tr></table></figure>

<p>将MySQL添加进环境变量:在/etc/profile末尾添加:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> MYSQL_HOME=/usr/local/mysql </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$MYSQL_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>

<p>随后用source命令使其生效</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>

<p>新建MySQL用户:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">groupadd mysql</span><br><span class="line">useradd -r -g mysql -s /bin/false mysql</span><br><span class="line"><span class="built_in">cd</span> /usr/local/mysql</span><br><span class="line"><span class="built_in">chown</span> -R mysql:mysql .</span><br><span class="line">scripts/mysql_install_db --user=mysql</span><br></pre></td></tr></table></figure>

<p>将当前目录的拥有者改为root</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chown</span> -R root</span><br></pre></td></tr></table></figure>

<p>修改当前data目录拥有者为mysql</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chown</span> -R mysql data</span><br><span class="line">bin/mysqld_safe --user=mysql &amp;</span><br></pre></td></tr></table></figure>

<p>用<code>bin/mysql</code>命令登录MySQL,成功后使用<code>exit;</code>命令退出即可</p>
<p>进行修改MySQL的root账户密码操作</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/mysql_secure_installation</span><br><span class="line"><span class="built_in">cp</span> support-files/mysql.server /etc/init.d/mysql.server</span><br></pre></td></tr></table></figure>

<p>查看MySQL的进程号并kill掉</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | grep mysql</span><br></pre></td></tr></table></figure>

<p>用普通用户配置访问权限:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;cluster&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION; </span><br><span class="line">mysql<span class="operator">&gt;</span> FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309193809638.png"></p>
<h3 id="3-2-测试"><a href="#3-2-测试" class="headerlink" title="3.2 测试"></a>3.2 测试</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">create</span> database test_table; </span><br><span class="line">mysql<span class="operator">&gt;</span> use test_table;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> userinfo(id <span class="type">int</span> <span class="keyword">not</span> <span class="keyword">null</span>); </span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">insert</span> <span class="keyword">into</span> userinfo <span class="keyword">values</span>(<span class="number">1</span>); </span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> userinfo;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">drop</span> database test_table;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309194232911.png"></p>
<h2 id="4-安装JDK"><a href="#4-安装JDK" class="headerlink" title="4. 安装JDK"></a>4. 安装JDK</h2><p>需要在每台机器上安装JDK,将jdk压缩包传到服务器<code>/usr/local</code>目录下并解压,修改环境变量:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/local/jdk1.8.0_102</span><br><span class="line"><span class="built_in">export</span> JRE_HOME=/usr/local/jdk1.8.0_102/jre</span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/lib:<span class="variable">$JRE_HOME</span>/lib:<span class="variable">$CLASSPATH</span> </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$JRE_HOME</span>/bin:<span class="variable">$JAVA_HOME</span>:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>

<p>配置完成,并使用scp命令将jdk复制到其他节点:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309205340946.png"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r /usr/local/jdk1.7.0_80/ cluster2:/usr/local/</span><br></pre></td></tr></table></figure>

<p>同样的方式将jdk目录写入环境变量</p>
<h2 id="5-安装Zookeeper"><a href="#5-安装Zookeeper" class="headerlink" title="5. 安装Zookeeper"></a>5. 安装Zookeeper</h2><p>最终需要在每一台机器上安装ZooKeeper:</p>
<p>在cluster1上将zookeeper的压缩包解压到/usr/local目录下,</p>
<p>并写入环境变量:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/usr/local/zookeeper-3.4.6 </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$ZOOKEEPER_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>

<p>随后在 /usr/local/zookeeper-3.4.6/conf/zoo.cfg中新建zoo.cfg文件,写入如下内容:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 客户端心跳时间(毫秒)    </span><br><span class="line">tickTime=2000</span><br><span class="line"># 允许心跳间隔的最大时间</span><br><span class="line">initLimit=10 </span><br><span class="line"># 同步时限</span><br><span class="line">syncLimit=5</span><br><span class="line"># 数据存储目录</span><br><span class="line">dataDir=/home/hadoop_files/hadoop_data/zookeeper</span><br><span class="line"># 数据日志存储目录</span><br><span class="line">dataLogDir=/home/hadoop_files/hadoop_logs/zookeeper/dataLog </span><br><span class="line"># 端口号</span><br><span class="line">clientPort=2181</span><br><span class="line"># 集群节点和服务端口配置</span><br><span class="line">server.1=cluster1:2888:3888 </span><br><span class="line">server.2=cluster2:2888:3888 </span><br><span class="line">server.3=cluster3:2888:3888</span><br></pre></td></tr></table></figure>

<p>接下来创建zookeeper的数据目录和日志存储目录, 并修改文件夹的权限:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /home/hadoop_files/hadoop_data/zookeeper</span><br><span class="line"><span class="built_in">mkdir</span> -p /home/hadoop_files/hadoop_logs/zookeeper/dataLog </span><br><span class="line"><span class="built_in">mkdir</span> -p /home/hadoop_files/hadoop_logs/zookeeper/logs</span><br><span class="line"></span><br><span class="line"><span class="built_in">chown</span> -R hadoop:hadoop /home/hadoop_files</span><br><span class="line"><span class="built_in">chown</span> -R hadoop:hadoop /usr/local/zookeeper-3.4.6</span><br></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309214332045.png"></p>
<p>在 cluster1 号服务器的 data 目录中创建一个文件 myid，输入内容为 1, 且myid 应与 zoo.cfg 中的集群节点相匹配, cluster2和cluster3就写2和3</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;1&quot;</span> &gt;&gt; /home/hadoop_files/hadoop_data/zookeeper/myid</span><br></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309214553265.png"></p>
<p>接下来修改zookeeper/目录下相关配置文件</p>
<p>修改 zookeeper 的日志输出路径(注意CDH 版与原生版配置文件不同)</p>
<blockquote>
<p>修改bin/zkEnv.sh中的部分如下所示:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;x<span class="variable">$&#123;ZOO_LOG_DIR&#125;</span>&quot;</span> = <span class="string">&quot;x&quot;</span> ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">ZOO_LOG_DIR=<span class="string">&quot;/home/hadoop_files/hadoop_logs/zookeeper/logs&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;x<span class="variable">$&#123;ZOO_LOG4J_PROP&#125;</span>&quot;</span> = <span class="string">&quot;x&quot;</span> ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">ZOO_LOG4J_PROP=<span class="string">&quot;INFO,ROLLINGFILE&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
</blockquote>
<p>然后修改conf/zookeeper的日志配置文件<code>log4j.properties</code>:</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">zookeeper.root.logger</span>=<span class="string">INFO,ROLLINGFILE log4j.appender.ROLLINGFILE=org.apache.log4j.DailyRollingFileAppender</span></span><br></pre></td></tr></table></figure>

<p>将zookeeper-3.4.6的内容复制到其他两个节点上:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r /usr/local/zookeeper-3.4.6 cluster2:/usr/local/ </span><br><span class="line">scp -r /usr/local/zookeeper-3.4.6 cluster3:/usr/local/</span><br></pre></td></tr></table></figure>

<p>接下来切换到hadoop用户,使用<code>source /etc/profile</code>刷新环境变量,随后启动zookeeper:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure>

<p>三台机器都把zookeeper启动之后用命令<code>jps</code>查看进程是否启动:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309234544293.png"></p>
<p>可以看到在每台机器上都能看到一个叫<em>QuorumPeerMain</em>的进程,说明启动成功</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309234950820.png"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309235011745.png"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309235023280.png"></p>
<p>可以看到三台机器中一台是leader,另两台是follower</p>
<p>zookeeper的关闭命令是<code>zkServer.sh stop</code></p>
<h2 id="6-安装Kafka"><a href="#6-安装Kafka" class="headerlink" title="6. 安装Kafka"></a>6. 安装Kafka</h2><h3 id="6-1-安装"><a href="#6-1-安装" class="headerlink" title="6.1 安装"></a>6.1 安装</h3><p>在cluster1上解压kafka到/usr/local</p>
<p>然后添加环境变量:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> KAFKA_HOME=/usr/local/kafka_2.10-0.8.2.1 </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$KAFKA_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>

<p>随后修改<code>kafka/config/server.properties</code>文件:</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 将brokers 的 id设为唯一的值,这里就把编号作为它的值, 即1,2,3</span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="string">1</span></span><br><span class="line"><span class="comment"># 2. 修改日志路径</span></span><br><span class="line"><span class="attr">log.dirs</span>=<span class="string">/home/hadoop_files/hadoop_logs/kafka</span></span><br><span class="line"><span class="comment"># 3. zookeeper集群的ip和端口, 用逗号隔开</span></span><br><span class="line"><span class="attr">zookeeper.connect</span>=<span class="string">cluster1:2181,cluster2:2181,cluster3:2181</span></span><br><span class="line"><span class="comment"># 4. 对应机器的ip地址!</span></span><br><span class="line"><span class="attr">advertised.host.name</span>=<span class="string">192.168.56.121</span></span><br></pre></td></tr></table></figure>

<p>创建logs文件夹:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /home/hadoop_files/hadoop_logs/kafka</span><br><span class="line"><span class="built_in">chown</span> -R hadoop:hadoop /home/hadoop_files</span><br><span class="line"><span class="built_in">chown</span> -R hadoop:hadoop /usr/local/kafka_2.10-0.8.2.1</span><br></pre></td></tr></table></figure>

<p>之后使用 hadoop 用户启动 kafka 集群<br>先启动 zookeeper 集群，然后在 kafka 集群中的每个节点使用,下面是启动命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-start.sh /usr/local/kafka_2.10-0.8.2.1/config/server.properties &amp;</span><br></pre></td></tr></table></figure>

<h3 id="6-2-测试"><a href="#6-2-测试" class="headerlink" title="6.2 测试"></a>6.2 测试</h3><p>使用hadoop用户执行命令,</p>
<p>创建topic</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --create --zookeeper cluster1:2181,cluster2:2181,cluster3:2181 --replication-factor 3 --partitions 1 --topic mykafka</span><br></pre></td></tr></table></figure>

<p>查看Topic</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --list --zookeeper cluster1:2181,cluster2:2181,cluster3:2181</span><br></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310002701290.png"></p>
<p>查看详细信息:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --describe --zookeeper cluster1:2181,cluster2:2181,cluster3:2181 </span><br></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310002812404.png"></p>
<p>在cluster1上执行如下命令用来发送消息:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list localhost:9092 --topic mykafka</span><br></pre></td></tr></table></figure>

<p>在cluster2上执行如下命令用来接收消息:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh -zookeeper cluster1:2181,cluster2:2181,cluster3:2181 --topic mykafka --from-beginning</span><br></pre></td></tr></table></figure>

<p>接着在cluster1上输入以下内容:</p>
<blockquote>
<p>test</p>
<p>mycluster test</p>
</blockquote>
<p>在cluster2上可以成功接收到相应信息</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310003237619.png"></p>
<p>在每台机器上执行<code>kafka-server-stop.sh</code>命令关闭kafka,随后在每台机器上用screen命令新建窗口在后台跑kafka集群</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">screen -S kafka</span><br><span class="line">kafka-server-start.sh /usr/local/kafka_2.10-0.8.2.1/config/server.properties</span><br></pre></td></tr></table></figure>

<p>随后使用Ctrl +  A + D退出新建的screen,用<code>jps</code>命令看到Kafka进程在运行</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310003857453.png"></p>
<h2 id="7-安装Hadoop"><a href="#7-安装Hadoop" class="headerlink" title="7. 安装Hadoop"></a>7. 安装Hadoop</h2><h3 id="7-1-安装"><a href="#7-1-安装" class="headerlink" title="7.1 安装"></a>7.1 安装</h3><p><strong>在启动Hadoop之前应先启动zookeeper</strong></p>
<p>以下命令若无特殊说明,均使用 用户hadoop执行</p>
<p>将 hadoop-2.6.5.tar.gz 解压到 /usr/local/ 目录下</p>
<p>进入hadoop配置文件目录:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local/hadoop-2.6.5/etc/hadoop</span><br></pre></td></tr></table></figure>

<p>修改hadoop-env.sh文件:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/local/jdk1.7.0_80</span><br><span class="line"><span class="built_in">export</span> HADOOP_PID_DIR=/home/hadoop_files</span><br></pre></td></tr></table></figure>

<p>配置mapred-env.sh</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_PID_DIR=/home/hadoop_files</span><br></pre></td></tr></table></figure>

<p>配置core-site.xml文件</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span> </span><br><span class="line">    <span class="comment">&lt;!-- 指定 hdfs的 nameservices名称为 mycluster，与 hdfs-site.xml的 HA配置相同 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://cluster1:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="comment">&lt;!-- 指定缓存文件存储的路径 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop_files/hadoop_tmp/hadoop/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置 hdfs文件被永久删除前保留的时间（单位：分钟），默认值为 0表明垃圾回收站功能关闭 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1440<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="comment">&lt;!-- 指定 zookeeper地址，配置 HA时需要 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster1:2181,cluster2:2181,cluster3:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>配置hdfs-site.xml文件</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span> </span><br><span class="line">    <span class="comment">&lt;!-- 指定 hdfs元数据存储的路径 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop_files/hadoop_data/hadoop/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 hdfs数据存储的路径 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop_files/hadoop_data/hadoop/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.secondary.http.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster1:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="comment">&lt;!-- 数据备份的个数 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 关闭权限验证 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 开启 WebHDFS功能（基于 REST的接口服务） --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>配置mapred-site.xml文件</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span> </span><br><span class="line">    <span class="comment">&lt;!-- 指定 MapReduce计算框架使用 YARN --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 jobhistory server的 rpc地址 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster1:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 jobhistory server的 http地址 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster1:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>配置yarn-site.xml文件</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span> </span><br><span class="line">    <span class="comment">&lt;!-- NodeManager上运行的附属服务，需配置成 mapreduce_shuffle才可运行 MapReduce程序 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置 Web Application Proxy安全代理（防止 yarn被攻击） --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.web-proxy.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster2:8888<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="comment">&lt;!-- 开启日志 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置日志删除时间为 7天， ，-1为禁用，单位为秒 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 修改日志目录 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.remote-app-log-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop_files/hadoop_logs/yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster1:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster1:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster1:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>配置slaves文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cluster1</span><br><span class="line">cluster2 </span><br><span class="line">cluster3</span><br></pre></td></tr></table></figure>

<p>在所有节点上创建如下目录,即上述配置涉及的目录:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /home/hadoop_files/hadoop_data/hadoop/namenode </span><br><span class="line"><span class="built_in">mkdir</span> -p /home/hadoop_files/hadoop_data/hadoop/datanode</span><br><span class="line"><span class="built_in">mkdir</span> -p /home/hadoop_files/hadoop_tmp/hadoop/data/tmp</span><br><span class="line"><span class="built_in">mkdir</span> -p /home/hadoop_files/hadoop_logs/yarn</span><br></pre></td></tr></table></figure>

<p>将cluster1的hadoop工作目录同步到集群其他节点:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r /usr/local/hadoop-2.6.5 cluster2:/usr/local/</span><br><span class="line">scp -r /usr/local/hadoop-2.6.5 cluster3:/usr/local/</span><br></pre></td></tr></table></figure>

<p>之后保证工作目录所有者为hadoop用户</p>
<p>每台机器新建环境变量如下, 并使之生效:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/local/hadoop-2.6.5</span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="variable">$HADOOP_HOME</span>/lib/native</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>

<p>启动zookeeper集群后开始格式化:</p>
<p>在所有节点上启动journalnode</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start journalnode</span><br></pre></td></tr></table></figure>

<p>使用jps可以看到journalnode进程</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310010351641.png"></p>
<p>在cluster1上执行格式化HDFS命令:<code>hdfs namenode -format, </code></p>
<p>之后使用<code>hadoop-daemon.sh stop journalnode</code>命令可在节点上关闭journalnode, </p>
<p>在cluster1上启用HDFS:<code>start-dfs.sh</code>, </p>
<p>可在cluster1上看到NameNode, DataNode, SecondaryNameNode;</p>
<p> 在cluster2和cluster3上看到DataNode:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310012508472.png"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310012522550.png"></p>
<p>在cluster1上启用YARN:<code>start-yarn.sh</code></p>
<p>启动后 cluster1 上使用 jps 可以看到NodeManager, ResourceManager, </p>
<p>cluster2 和 cluster3 上可以看到NodeManager:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310012949160.png"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310013004848.png"></p>
<h3 id="7-2-测试"><a href="#7-2-测试" class="headerlink" title="7.2 测试"></a>7.2 测试</h3><p>启动HDFS 后，可以在浏览器中，打开 <a target="_blank" rel="noopener" href="http://192.168.56.121:50070/">http://192.168.56.121:50070</a>，可以看到HDFS 的 web 界面:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310013155182.png"></p>
<p>上图第一页是当前HDFS 的概况，里面显示了HDFS 的启动时间，版本等信息。</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310013244551.png"></p>
<p>Datanodes页面显示了当前HDFS 中的可用节点。</p>
<p>启用YARN后可以通过访问<a target="_blank" rel="noopener" href="http://192.168.56.121:8088/">http://192.168.56.121:8088</a>查看YARN的web界面</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310013421172.png"></p>
<p>该页面展示了所有提交到 YARN 上的程序，点击左侧的Nodes 可以看到 YARN 的节点:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310090014904.png" alt="image-20220310090014904"></p>
<p>此处每个节点的可用内存 Mem Avail 为 8G，而我们的虚拟机每台内存只有 1.5G，由于没有在 yarn-site.xml 这个文件中对节点的可用内存进行配置出现了此问题，可以增加以下内容进行配置：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 配置 nodemanager 可用的资源内存 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>20480<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置 nodemanager 可用的资源 CPU --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>24<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>



<p>进行命令行测试:</p>
<p>在cluster1上,</p>
<p>首先切换到hadoop用户目录:<code>cd ~/</code></p>
<p>新建一个测试文件:<code>Vi testfile</code></p>
<p>输入:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td></tr></table></figure>

<p>保存之后退出</p>
<p>在 HDFS 的根目录创建 test 目录: <code>hdfs dfs -mkdir /test</code></p>
<p>查看HDFS 根目录的文件: <code>hdfs dfs -ls /</code></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310014227354.png"></p>
<p>将测试文件 testfile 上传至 HDFS 根目录下的 test 目录中: <code>hdfs dfs -put testfile /test</code></p>
<p>在cluster2上,</p>
<p>首先切换到hadoop用户目录:<code>cd ~/</code></p>
<p>查看HDFS 根目录: <code>hdfs dfs -ls /</code></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310014513363.png"></p>
<p>查看HDFS 根目录下的 test 目录，看到刚才在 cluster1 上上传的文件 testfile: <code>hdfs dfs -ls /test</code></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310014603118.png"></p>
<p>使用<code>hdfs dfs -get /test/testfile</code>将testfile下载到本地,</p>
<p>再查看当前目录下的文件可以发现testfile,</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310014808596.png" alt="image-20220310014808596"></p>
<h2 id="8-安装HBase"><a href="#8-安装HBase" class="headerlink" title="8. 安装HBase"></a>8. 安装HBase</h2><h3 id="8-1-安装"><a href="#8-1-安装" class="headerlink" title="8.1 安装"></a>8.1 安装</h3><p><strong>HBase 启动的先决条件是 zookeeper 和Hadoop 已经启动</strong></p>
<p>在cluster1上, 将hbase-1.2.6-bin.tar.gz解压到/usr/local/目录下,随后修改<code>/usr/local/hbase-1.2.6/conf/</code>目录下的hbase-env.sh如下:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置 JDK 安装路径</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/local/jdk1.7.0_80 </span><br><span class="line"><span class="comment"># 配置 Hadoop 安装路径</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/local/hadoop-2.6.5 </span><br><span class="line"><span class="comment"># 设置 HBase 的日志目录</span></span><br><span class="line"><span class="built_in">export</span> HBASE_LOG_DIR=/home/hadoop_files/hadoop_logs/hbase/logs </span><br><span class="line"><span class="comment"># 使用独立的ZooKeeper 集群</span></span><br><span class="line"><span class="built_in">export</span> HBASE_MANAGES_ZK=<span class="literal">false</span> </span><br><span class="line"><span class="comment"># 设置 pid 的路径</span></span><br><span class="line"><span class="built_in">export</span> HBASE_PID_DIR=/home/hadoop_files</span><br></pre></td></tr></table></figure>

<p>配置hbase-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://cluster1:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.master<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>60000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>		    </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop_files/hadoop_tmp/hbase/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster1,cluster2,cluster3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> 	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop_files/hadoop_data/zookeeper<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> 	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.clientPort<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>zookeeper.session.timeout<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>120000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.regionserver.restart.on.zk.expire<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.master.info.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>60010<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>配置regionservers</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cluster1</span><br><span class="line">cluster2</span><br><span class="line">cluster3</span><br></pre></td></tr></table></figure>

<p>删除hbase的slf4j-log4j12-1.7.5.jar, 解决hbase和hadoop的LSF4J冲突,</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> /usr/local/hbase-1.2.6/lib/slf4j-log4j12-1.7.5.jar /usr/local/hbase-1.2.6/lib/slf4j-log4j12-1.7.5.jar.bk</span><br></pre></td></tr></table></figure>

<p>将 hbase 工作目录同步到集群其它节点</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r /usr/local/hbase-1.2.6/ cluster2:/usr/local/ </span><br><span class="line">scp -r /usr/local/hbase-1.2.6/ cluster3:/usr/local/</span><br></pre></td></tr></table></figure>

<p>在所有节点创建 hbase 的缓存文件目录和日志文件目录,并修改相应权限</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /home/hadoop_files/hadoop_tmp/hbase/tmp</span><br><span class="line"><span class="built_in">mkdir</span> -p /home/hadoop_files/hadoop_logs/hbase/logs</span><br><span class="line"><span class="built_in">chown</span> -R hadoop:hadoop /usr/local/hbase-1.2.6 </span><br><span class="line"><span class="built_in">chown</span> -R hadoop:hadoop /home/hadoop_files</span><br></pre></td></tr></table></figure>

<p>Hbase的环境变量如下:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HBASE_HOME=/usr/local/hbase-1.2.6 </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$HBASE_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>

<p>在cluster1上,先启动zookeeper, Hadoop的HDFS和YARN,然后才能启动HBase,</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br><span class="line">start-yarn.sh</span><br><span class="line">start-hbase.sh</span><br></pre></td></tr></table></figure>

<p>启动后在cluster1上使用<code>jps</code>可以看到HMaster和HRegionServer,</p>
<p>cluster2和cluster3上可以看到HRegionServer</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310085135752.png" alt="image-20220310085135752"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310085202547.png" alt="image-20220310085202547"></p>
<h3 id="8-2-测试"><a href="#8-2-测试" class="headerlink" title="8.2 测试"></a>8.2 测试</h3><p>打开<a target="_blank" rel="noopener" href="http://192.168.56.121:60010/">http://192.168.56.121:60010</a>查看Hbase的web界面</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310090107851.png"></p>
<p>在cluster1上, 输入<code>hbase shell</code> 进入hbase shell.键入以下命令:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">hbase&gt; </span><span class="language-bash">create <span class="string">&#x27;userinfotable&#x27;</span>,&#123;NAME=&gt;<span class="string">&#x27;username&#x27;</span>&#125;,&#123;NAME=&gt;<span class="string">&#x27;fullname&#x27;</span>&#125;,&#123;NAME=&gt;<span class="string">&#x27;homedir&#x27;</span>&#125;</span> </span><br><span class="line"><span class="meta prompt_">hbase&gt; </span><span class="language-bash">put <span class="string">&#x27;userinfotable&#x27;</span>,<span class="string">&#x27;r1&#x27;</span>,<span class="string">&#x27;username&#x27;</span>,<span class="string">&#x27;vcsa&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">hbase&gt; </span><span class="language-bash">put <span class="string">&#x27;userinfotable&#x27;</span>,<span class="string">&#x27;r2&#x27;</span>,<span class="string">&#x27;username&#x27;</span>,<span class="string">&#x27;sasuser&#x27;</span></span> </span><br><span class="line"><span class="meta prompt_">hbase&gt; </span><span class="language-bash">scan <span class="string">&#x27;userinfotable&#x27;</span></span></span><br></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310091241471.png" alt="image-20220310091241471"></p>
<p>在 web 界面也可以看到刚才建立的表:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310091504388.png" alt="image-20220310091504388"></p>
<p>删除刚才建立的表：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">hbase&gt; </span><span class="language-bash"><span class="built_in">disable</span> <span class="string">&#x27;userinfotable&#x27;</span></span> </span><br><span class="line"><span class="meta prompt_">hbase&gt; </span><span class="language-bash">drop <span class="string">&#x27;userinfotable&#x27;</span></span> </span><br><span class="line"><span class="meta prompt_">hbase&gt; </span><span class="language-bash"><span class="built_in">exit</span></span></span><br></pre></td></tr></table></figure>

<h2 id="9-安装Hive"><a href="#9-安装Hive" class="headerlink" title="9. 安装Hive"></a>9. 安装Hive</h2><h3 id="9-1-安装"><a href="#9-1-安装" class="headerlink" title="9.1 安装"></a>9.1 安装</h3><p><strong>hive 能启动的先决条件是 MySQL 已经安装并配置完成，而且 HDFS 也要启动之后才能运行 hive</strong></p>
<p>将apache-hive-1.1.0-bin.tar.gz上传到<code>/usr/local</code>并解压</p>
<p>添加环境变量:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HIVE_HOME=/usr/local/apache-hive-1.1.0-bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$HIVE_HOME</span>/bin:<span class="variable">$HIVE_HOME</span>/conf:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>

<p>使用root用户登录MySQL:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p</span><br></pre></td></tr></table></figure>

<p>创建用户hive, 密码hive:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">GRANT</span> USAGE <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;hive&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;hive&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br></pre></td></tr></table></figure>

<p>创建数据库hive</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">create</span> database hive;</span><br></pre></td></tr></table></figure>

<p>允许任意 ip 以hive 登陆数据库</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">on</span> hive.<span class="operator">*</span> <span class="keyword">to</span> hive@<span class="string">&#x27;%&#x27;</span> identified <span class="keyword">by</span> <span class="string">&#x27;hive&#x27;</span>; </span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">on</span> hive.<span class="operator">*</span> <span class="keyword">to</span> hive@<span class="string">&#x27;localhost&#x27;</span> identified <span class="keyword">by</span> <span class="string">&#x27;hive&#x27;</span>; </span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">on</span> hive.<span class="operator">*</span> <span class="keyword">to</span> hive@<span class="string">&#x27;cluster2&#x27;</span> identified <span class="keyword">by</span> <span class="string">&#x27;hive&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>刷新权限并退出:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> flush privileges;</span><br><span class="line">mysql<span class="operator">&gt;</span> exit;</span><br></pre></td></tr></table></figure>

<p>验证hive用户是否正确创建:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310093902048.png"></p>
<p>接下来修改hive-site.xml</p>
<p>将提供的hive-site.xml上传到apache-hive-1.1.0-bin/conf/目录下即可</p>
<p>将mysql-connector-java-5.1.43-bin.jar上传至 /usr/local/apache-hive-1.1.0-bin/lib/,</p>
<p>将jline-2.12.jar拷贝到/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /usr/local/apache-hive-1.1.0-bin/lib/jline-2.12.jar /usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/</span><br></pre></td></tr></table></figure>

<p>并将原先存在的jline-0.9.94.jar重命名为jline-0.9.94.jar.bak,</p>
<p>切换到hadoop用户执行:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /home/hadoop_files/hadoop_tmp/hive/iotmp</span><br><span class="line">mkdir -p /home/hadoop_files/hadoop_logs/hive/querylog</span><br></pre></td></tr></table></figure>

<h2 id="10-安装Scala"><a href="#10-安装Scala" class="headerlink" title="10. 安装Scala"></a>10. 安装Scala</h2><p>在cluster1上将scala-2.10.6.tgz解压到/usr/local/目录下,</p>
<p>环境变量为:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SCALA_HOME=/usr/local/scala-2.10.6</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$SCALA_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>

<p>刷新环境变量后用<code>scala -version</code>查看Scala版本验证安装:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310115940338.png"></p>
<p>复制到所有的服务器上</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r /usr/local/scala-2.10.6 cluster2:/usr/local/ </span><br><span class="line">scp -r /usr/local/scala-2.10.6 cluster3:/usr/local/</span><br></pre></td></tr></table></figure>

<p>之后设置环境变量,并且修改文件夹权限:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chown</span> -R hadoop:hadoop /usr/local/scala-2.10.6</span><br></pre></td></tr></table></figure>

<h2 id="11-安装Spark"><a href="#11-安装Spark" class="headerlink" title="11. 安装Spark"></a>11. 安装Spark</h2><h3 id="11-1-安装"><a href="#11-1-安装" class="headerlink" title="11.1 安装"></a>11.1 安装</h3><p>将spark-1.6.3-bin-hadoop2.6.tgz解压到/usr/local</p>
<p>环境变量为:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/local/spark-1.6.3-bin-hadoop2.6 </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$SPARK_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="comment"># cluster1作为主节点需要再加一行</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$SPARK_HOME</span>/sbin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>

<p>在 conf 文件夹里面复制一份 template，改名为 spark-env.sh</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> conf/spark-env.sh.template conf/spark-env.sh</span><br></pre></td></tr></table></figure>

<p>并在其中添加以下语句:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/local/jdk1.7.0_80 </span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/usr/local/scala-2.10.6 </span><br><span class="line"><span class="built_in">export</span> SPARK_MASTER_IP=cluster1</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/usr/local/hadoop-2.6.5/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> SPARK_DIST_CLASSPATH=$(/usr/local/hadoop-2.6.5/bin/hadoop classpath) </span><br><span class="line"><span class="built_in">export</span> SPARK_CLASSPATH=<span class="variable">$HIVE_HOME</span>/lib/mysql-connector-java-5.1.43-bin.jar </span><br><span class="line"><span class="built_in">export</span> SPARK_PID_DIR=/home/hadoop_files</span><br></pre></td></tr></table></figure>

<p>在conf下新建slaves文件,内容为:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cluster1</span><br><span class="line">cluster2</span><br><span class="line">cluster3</span><br></pre></td></tr></table></figure>

<p>将 hive 目录下 conf 文件夹中的 hive-site.xml 复制到 spark 的 conf 目录下,</p>
<p>将 hadoop/etc/hadoop 文件中的 hdfs-site.xml 和 core-site.xml 文件复制到 spark 的 conf 目录下,</p>
<p>将 conf 目录下的 spark-defaults.conf.template 复制一份，改名为 spark-default.conf ,并在最下面加上一行:<code>spark.files file:///usr/local/spark-1.6.3-bin-hadoop2.6/conf/hdfs-site.xml,file:///usr/local/spark-1.6.3-binhadoop2.6/conf/core-site.xml</code></p>
<p>复制到所有的服务器上</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r /usr/local/spark-1.6.3-bin-hadoop2.6 cluster2:/usr/local/ </span><br><span class="line">scp -r /usr/local/spark-1.6.3-bin-hadoop2.6 cluster3:/usr/local/</span><br></pre></td></tr></table></figure>

<p>修改 spark 文件夹的权限（每个 spark 结点）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chown</span> -R hadoop:hadoop /usr/local/spark-1.6.3-bin-hadoop2.6</span><br></pre></td></tr></table></figure>

<p>在cluster1上运行Spark</p>
<p>运行 spark 前需启动 hadoop 的HDFS 和 YARN</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start-master.sh</span><br><span class="line">start-slaves.sh</span><br></pre></td></tr></table></figure>

<blockquote>
<p>关闭 Spark 的命令（cluster1 上）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">stop-slaves.sh</span><br><span class="line">stop-master.sh</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="11-2-测试"><a href="#11-2-测试" class="headerlink" title="11.2 测试"></a>11.2 测试</h3><p>在 cluster1 上使用 jps 命令可以看到 Master 和 Worker，cluster2 和 3 上可以看到Worker,</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310122903560.png"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310122926901.png"></p>
<p>用浏览器访问 &lt;<a target="_blank" rel="noopener" href="http://192.168.56.121:8080/">http://192.168.56.121:8080</a> &gt;可以看到 Spark 的web 界面，可以看到 3 个worker</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310122837660.png"></p>
<h2 id="12-安装Storm"><a href="#12-安装Storm" class="headerlink" title="12. 安装Storm"></a>12. 安装Storm</h2><p>storm需要Python2.6以上版本</p>
<p>将apache-storm-1.1.1.tar.gz解压到<code>/usr/local/</code>下,</p>
<p>环境变量添加:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> STORM_HOME=/usr/local/apache-storm-1.1.1 </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$STORM_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>

<p>改一下权限</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chown</span> -R hadoop:hadoop apache-storm-1.1.1</span><br></pre></td></tr></table></figure>

<p>更改storm/conf/storm.yaml文件:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">storm.zookeeper.servers :</span></span><br><span class="line"><span class="string">-</span>	<span class="string">“cluster1”</span></span><br><span class="line"><span class="string">-</span>	<span class="string">“cluster2”</span></span><br><span class="line"><span class="string">-</span>	<span class="string">“cluster3”</span></span><br><span class="line"> <span class="attr">storm.local.dir :</span> <span class="string">“/home/hadoop_files/hadoop_tmp/storm/tmp”</span></span><br></pre></td></tr></table></figure>

<p>新建tmp文件夹,改权限:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /home/hadoop_files/hadoop_tmp/storm/tmp </span><br><span class="line"><span class="built_in">chown</span> -R hadoop:hadoop /home/hadoop_files</span><br><span class="line"><span class="built_in">chown</span> -R hadoop:hadoop /usr/local/apache-storm-1.1.1</span><br></pre></td></tr></table></figure>

<p>在cluster1上新建storm-master的虚拟窗口</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">screen -S storm-master</span><br><span class="line">storm nimbus</span><br></pre></td></tr></table></figure>

<p>随后将窗口挂到后台</p>
<p>在cluster2,3上新建storm-supervisor的虚拟窗口</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">screen -S storm-master</span><br><span class="line">storm supervisor</span><br></pre></td></tr></table></figure>

<p>随后将窗口挂到后台</p>
<p>在cluster1上新建storm-ui的虚拟窗口</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">screen -S storm-ui</span><br><span class="line">storm ui</span><br></pre></td></tr></table></figure>

<p>随后将窗口挂到后台</p>
<p>在cluster1,2,3上新建storm-logviewer的虚拟窗口</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">screen -S storm-logviewer</span><br><span class="line">storm logviewer</span><br></pre></td></tr></table></figure>

<p>随后将窗口挂到后台</p>
<p>使用 jps 可以看到以下进程</p>
<p>cluster1：nimbus, core, logviewer</p>
<p>cluster2：Supervisor, logviewer</p>
<p>cluster3：Supervisor, logviewer</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310130740038.png"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310130759287.png"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://www.ckxgzxa.top">残魁斜罡</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://www.ckxgzxa.top/HadoopContructionOnVM.html">https://www.ckxgzxa.top/HadoopContructionOnVM.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.ckxgzxa.top" target="_blank">技术匝记簿</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/blogpictures/202312060211044.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat_pay.png" target="_blank"><img class="post-qr-code-img" src="/img/wechat_pay.png" alt="微信扫码"/></a><div class="post-qr-code-desc">微信扫码</div></li><li class="reward-item"><a href="https://qr.alipay.com/lpx08506gp8hbu7m1bih892" target="_blank"><img class="post-qr-code-img" src="/img/alipay.png" alt="支付宝扫码"/></a><div class="post-qr-code-desc">支付宝扫码</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/htmllearning.html" title="HTML常见标签"><img class="cover" src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/blogpictures/202312060211788.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">HTML常见标签</div></div></a></div><div class="next-post pull-right"><a href="/mcpe_level_intro.html" title="MCPE 我的世界基岩版level.dat相关配置"><img class="cover" src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/blogpictures/202312060211044.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">MCPE 我的世界基岩版level.dat相关配置</div></div></a></div></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="utterances-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">残魁斜罡</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">68</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">20</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ckxgzxa"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ckxgzxa" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:ckxgzxa@ckxgzxa.top" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a><a class="social-icon" href="https://t.me/ckxgzxa" target="_blank" title="Telegram"><i class="fab fa-telegram" style="color: #0088cc;"></i></a><a class="social-icon" href="https://twitter.com/ckxgzxabest" target="_blank" title="Twitter"><i class="fab fa-twitter" style="color: #1da1f2;"></i></a><a class="social-icon" href="https://www.instagram.com/ckxgzxa" target="_blank" title="Instagram"><i class="fab fa-instagram" style="color: #e1306c;"></i></a><a class="social-icon" href="https://weibo.com/u/5657042189" target="_blank" title="Weibo"><i class="fab fa-weibo" style="color: #e6162d;"></i></a><a class="social-icon" href="/img/%E5%85%AC%E4%BC%97%E5%8F%B7%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" target="_blank" title="Wechat"><i class="fab fa-brands fa-weixin" style="color: #7bb32e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">有朋自远方来，不亦乐乎!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%90%AD%E5%BB%BAHadoop%E9%9B%86%E7%BE%A4"><span class="toc-number">1.</span> <span class="toc-text">虚拟机搭建Hadoop集群</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%88%9B%E5%BB%BA%E8%99%9A%E6%8B%9F%E6%9C%BA"><span class="toc-number">1.1.</span> <span class="toc-text">1. 创建虚拟机</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"><span class="toc-number">1.2.</span> <span class="toc-text">2. 准备工作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99%E5%92%8C-Selinux"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1 关闭防火墙和 Selinux</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E6%A3%80%E6%9F%A5%E7%BD%91%E5%8D%A1%E6%98%AF%E5%90%A6%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.2 检查网卡是否开机自启</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6"><span class="toc-number">1.2.3.</span> <span class="toc-text">2.3 安装软件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E4%BF%AE%E6%94%B9hosts"><span class="toc-number">1.2.4.</span> <span class="toc-text">2.4 修改hosts</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-%E6%96%B0%E5%BB%BA%E7%94%A8%E4%BA%8E%E7%BB%B4%E6%8A%A4%E9%9B%86%E7%BE%A4%E7%9A%84hadoop%E7%94%A8%E6%88%B7"><span class="toc-number">1.2.5.</span> <span class="toc-text">2.5 新建用于维护集群的hadoop用户</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-6-%E7%94%9F%E6%88%90SSH%E5%AF%86%E9%92%A5%E5%B9%B6%E5%88%86%E5%8F%91"><span class="toc-number">1.2.6.</span> <span class="toc-text">2.6 生成SSH密钥并分发</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-7-%E5%AE%89%E8%A3%85NTP%E6%9C%8D%E5%8A%A1"><span class="toc-number">1.2.7.</span> <span class="toc-text">2.7 安装NTP服务</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E5%AE%89%E8%A3%85MySQL"><span class="toc-number">1.3.</span> <span class="toc-text">3. 安装MySQL</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E5%AE%89%E8%A3%85"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E6%B5%8B%E8%AF%95"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 测试</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E5%AE%89%E8%A3%85JDK"><span class="toc-number">1.4.</span> <span class="toc-text">4. 安装JDK</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E5%AE%89%E8%A3%85Zookeeper"><span class="toc-number">1.5.</span> <span class="toc-text">5. 安装Zookeeper</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E5%AE%89%E8%A3%85Kafka"><span class="toc-number">1.6.</span> <span class="toc-text">6. 安装Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-%E5%AE%89%E8%A3%85"><span class="toc-number">1.6.1.</span> <span class="toc-text">6.1 安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-%E6%B5%8B%E8%AF%95"><span class="toc-number">1.6.2.</span> <span class="toc-text">6.2 测试</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E5%AE%89%E8%A3%85Hadoop"><span class="toc-number">1.7.</span> <span class="toc-text">7. 安装Hadoop</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-%E5%AE%89%E8%A3%85"><span class="toc-number">1.7.1.</span> <span class="toc-text">7.1 安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-%E6%B5%8B%E8%AF%95"><span class="toc-number">1.7.2.</span> <span class="toc-text">7.2 测试</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E5%AE%89%E8%A3%85HBase"><span class="toc-number">1.8.</span> <span class="toc-text">8. 安装HBase</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-%E5%AE%89%E8%A3%85"><span class="toc-number">1.8.1.</span> <span class="toc-text">8.1 安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-%E6%B5%8B%E8%AF%95"><span class="toc-number">1.8.2.</span> <span class="toc-text">8.2 测试</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-%E5%AE%89%E8%A3%85Hive"><span class="toc-number">1.9.</span> <span class="toc-text">9. 安装Hive</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-1-%E5%AE%89%E8%A3%85"><span class="toc-number">1.9.1.</span> <span class="toc-text">9.1 安装</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-%E5%AE%89%E8%A3%85Scala"><span class="toc-number">1.10.</span> <span class="toc-text">10. 安装Scala</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-%E5%AE%89%E8%A3%85Spark"><span class="toc-number">1.11.</span> <span class="toc-text">11. 安装Spark</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-1-%E5%AE%89%E8%A3%85"><span class="toc-number">1.11.1.</span> <span class="toc-text">11.1 安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-2-%E6%B5%8B%E8%AF%95"><span class="toc-number">1.11.2.</span> <span class="toc-text">11.2 测试</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-%E5%AE%89%E8%A3%85Storm"><span class="toc-number">1.12.</span> <span class="toc-text">12. 安装Storm</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/OracleDB02.html" title="2. Oracle学习笔记-Oracle的体系结构"><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/blogpictures/202312060210380.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2. Oracle学习笔记-Oracle的体系结构"/></a><div class="content"><a class="title" href="/OracleDB02.html" title="2. Oracle学习笔记-Oracle的体系结构">2. Oracle学习笔记-Oracle的体系结构</a><time datetime="2023-12-04T15:04:25.000Z" title="发表于 2023-12-04 23:04:25">2023-12-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/OracleDB01.html" title="1.Oracle学习笔记-Oracle 19c概述"><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/blogpictures/202312060212846.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="1.Oracle学习笔记-Oracle 19c概述"/></a><div class="content"><a class="title" href="/OracleDB01.html" title="1.Oracle学习笔记-Oracle 19c概述">1.Oracle学习笔记-Oracle 19c概述</a><time datetime="2023-12-02T19:41:37.000Z" title="发表于 2023-12-03 03:41:37">2023-12-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/road2docker04.html" title="04.Docker Compose"><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/blogpictures/202312060211788.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="04.Docker Compose"/></a><div class="content"><a class="title" href="/road2docker04.html" title="04.Docker Compose">04.Docker Compose</a><time datetime="2023-08-13T05:37:38.000Z" title="发表于 2023-08-13 13:37:38">2023-08-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/road2docker03.html" title="03.Dockerfile"><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/blogpictures/202312060210380.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="03.Dockerfile"/></a><div class="content"><a class="title" href="/road2docker03.html" title="03.Dockerfile">03.Dockerfile</a><time datetime="2023-08-12T16:06:58.000Z" title="发表于 2023-08-13 00:06:58">2023-08-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/road2docker02.html" title="02.Docker 镜像"><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/blogpictures/202312060213891.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="02.Docker 镜像"/></a><div class="content"><a class="title" href="/road2docker02.html" title="02.Docker 镜像">02.Docker 镜像</a><time datetime="2023-08-12T14:01:23.000Z" title="发表于 2023-08-12 22:01:23">2023-08-12</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2023 By 残魁斜罡</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><a href="http://beian.miit.gov.cn/" target="_blank">湘ICP备2021018734号</a><span class="footer-separator">|</span><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=43052102000188" target="_blank"><img src="/img/police_beian.png" alt="备案图标"/><span>湘公网安备 43052102000188号</span></a></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(() => {
  const loadUtterances = () => {
    let ele = document.createElement('script')
    ele.id = 'utterances_comment'
    ele.src = 'https://utteranc.es/client.js'
    ele.setAttribute('repo', 'CKXGZXA/GitPageComments')
    ele.setAttribute('issue-term', 'pathname')
    const nowTheme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'photon-dark' : 'github-light'
    ele.setAttribute('theme', nowTheme)
    ele.crossOrigin = 'anonymous'
    ele.async = true
    document.getElementById('utterances-wrap').appendChild(ele)
  }

  const utterancesTheme = theme => {
    const iframe = document.querySelector('.utterances-frame')
    if (iframe) {
      const theme = theme === 'dark' ? 'photon-dark' : 'github-light'
      const message = {
        type: 'set-theme',
        theme: theme
      };
      iframe.contentWindow.postMessage(message, 'https://utteranc.es');
    }
  }

  btf.addGlobalFn('themeChange', utterancesTheme, 'utterances')

  if ('Utterances' === 'Utterances' || !false) {
    if (false) btf.loadComment(document.getElementById('utterances-wrap'), loadUtterances)
    else loadUtterances()
  } else {
    window.loadOtherComment = loadUtterances
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>