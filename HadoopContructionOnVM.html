

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="baidu-site-verification" content="code-HJwAkkohj2" />
  <meta name="sogou_site_verification" content="2t6zxaPafe" />
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="残魁斜罡">
  <meta name="keywords" content="">
  
  <title>虚拟机搭建Hadoop集群 - 技术匝记簿</title>

  <link  rel="stylesheet" href="https://www.unpkg.com/bootstrap@4.5.3/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://www.unpkg.com/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://www.unpkg.com/highlight.js@10.6.0/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://www.unpkg.com/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"www.ckxgzxa.top","root":"/","version":"1.8.10","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":false,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":"01f66cc4caefba46f8cad22b739f765a","google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}}};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="技术匝记簿" type="application/atom+xml">
</head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>残魁斜罡的小小簿记</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/%E9%A3%8E%E6%99%AF.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="虚拟机搭建Hadoop集群">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-03-07 17:12" pubdate>
        2022年3月7日 下午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      6k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      89
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">虚拟机搭建Hadoop集群</h1>
            
              <p class="note note-info">
                
                  本文最后更新于：2022年4月14日 晚上
                
              </p>
            
            <div class="markdown-body">
              <h1 id="虚拟机搭建Hadoop集群"><a href="#虚拟机搭建Hadoop集群" class="headerlink" title="虚拟机搭建Hadoop集群"></a>虚拟机搭建Hadoop集群</h1><h2 id="1-创建虚拟机"><a href="#1-创建虚拟机" class="headerlink" title="1. 创建虚拟机"></a>1. 创建虚拟机</h2><p>下载VirtualBox或其他虚拟机软件并安装.</p>
<p>进入管理菜单-&gt;全局设置-&gt;网络-&gt;添加新NAT网络, 勾选启用网络并开启DHCP,确认即可.</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307172344864.png"></p>
<p>随后点击新建虚拟机, 将名称改为cluster1, 虚拟机类型选择Linux, Red Hat(64位),</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307172741873.png"></p>
<p>将内存大小改为1536MB,点击下一步</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307172827900.png"></p>
<p>选择现在创建虚拟硬盘(VHD, 动态分配, 8G), 点击创建即可成功创建虚拟机:</p>
<p>如下图所示,</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307173039991.png"></p>
<p>进入刚刚新建的虚拟机设置, 在网卡1处连接方式选择NAT网络, 在网卡2处勾选启用网络连接,连接方式设为: 仅主机(Host-Only)网络,点击OK即可,网络信息如下所示,</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307173502018.png"></p>
<p>然后选择存储设置, 加载CentOS7系统镜像到光驱</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307173709989.png"></p>
<p>确认之后将虚拟机启动,</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307173833389.png"></p>
<p>单击界面,让Virtual Box捕获鼠标(注:右Ctrl键可以接触捕获), 上移光标至Install CentOS 7处按回车键进行系统安装,</p>
<p>随后单击Continue</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307174203851.png"></p>
<p>将时区更改为: :earth_asia: Asia, Shanghai</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307174519139.png"></p>
<p>磁盘分区默认即可,</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307175112388.png"></p>
<p>随后设置用户名和密码, 如果密码不符合安全要求, 会需要点击两次以确认,耐心等待系统安装完成,然后点击重启按钮, 系统即安装完成</p>
<p>另外创建两台配置一样的虚拟机, 用户名分别为 cluster2 和 cluster3.</p>
<h2 id="2-准备工作"><a href="#2-准备工作" class="headerlink" title="2. 准备工作"></a>2. 准备工作</h2><h3 id="2-1-关闭防火墙和-Selinux"><a href="#2-1-关闭防火墙和-Selinux" class="headerlink" title="2.1 关闭防火墙和 Selinux"></a>2.1 关闭防火墙和 Selinux</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">// 关闭防火墙并阻止服务开机启动<br><span class="hljs-comment"># systemctl stop firewalld.service</span><br><span class="hljs-comment"># systemctl disable firewalld.service</span><br></code></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307181250561.png"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">// 编辑Selinux配置文件关闭Selinux<br><span class="hljs-comment"># vi /etc/selinux/config</span><br>// 将SELINUX设为disabled<br>// 重启<br><span class="hljs-comment"># reboot</span><br>// 用root用户查看Selinux状态<br><span class="hljs-comment"># getenforce</span><br></code></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307181417466.png"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220307181459557.png"></p>
<p>另两台虚拟机进行同样的操作.</p>
<h3 id="2-2-检查网卡是否开机自启"><a href="#2-2-检查网卡是否开机自启" class="headerlink" title="2.2 检查网卡是否开机自启"></a>2.2 检查网卡是否开机自启</h3><p>使用<code>ip addr</code>命令查看网卡名称,</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220308010929988.png"></p>
<p>可见两张网卡均未启用,</p>
<p>接下来编辑第一张网卡的配置文件, 修改如下文件<code>/etc/sysconfig/network-scripts/ifcfg-enp0s3</code>,将其中的ONBOOT项修改为yes,使网卡能够开机自启,</p>
<p>随后编辑第二章网卡的配置文件<code>etc/sysconfig/network-scripts/ifcfg-enp0s8</code>, 将BOOTPROTO设置为none, ONBOOT同样改为yes,并新增如下项:</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">IPADDR</span>=<span class="hljs-number">192.168</span>.<span class="hljs-number">56.121</span>  <span class="hljs-comment"># cluster2为192.168.56.122, cluster3为192.168.56.123</span><br><span class="hljs-attr">NETMASK</span>=<span class="hljs-number">255.255</span>.<span class="hljs-number">255.0</span><br><span class="hljs-attr">NETWORK</span>=<span class="hljs-number">192.168</span>.<span class="hljs-number">56.0</span><br></code></pre></td></tr></table></figure>

<p>保存之后, 重启网络服务发现配置成功</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220308011832168.png"></p>
<p>将另外两台机器也配置完成,进入下一步,</p>
<p>将网络配置成功之后我们就可以使用SSH工具连接虚拟机了,在这里我使用Finalshell工具进行连接:</p>
<p>添加如下所示的三个连接就可以连上虚拟机了:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220308012637088.png"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220308012706054.png"></p>
<p>对于文件传输功能, Finalshell有集成功能可以方便的拖拽文件进行上传和下载操作.</p>
<h3 id="2-3-安装软件"><a href="#2-3-安装软件" class="headerlink" title="2.3 安装软件"></a>2.3 安装软件</h3><p>每台机器上都要安装,</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">yum install perl*  ntpdate  libaio  screen -y<br></code></pre></td></tr></table></figure>

<h3 id="2-4-修改hosts"><a href="#2-4-修改hosts" class="headerlink" title="2.4 修改hosts"></a>2.4 修改hosts</h3><p>将每台机器的ip写入每台机器的hosts文件</p>
<figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">10.0.2.8</span> cluster1<br><span class="hljs-number">10.0.2.4</span> cluster2<br><span class="hljs-number">10.0.2.9</span> cluster3<br></code></pre></td></tr></table></figure>

<p>修改之后测试网络连通性, 在cluster1上 ping 另两台机器:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220308183616945.png"></p>
<p>可见hosts文件生效.</p>
<h3 id="2-5-新建用于维护集群的hadoop用户"><a href="#2-5-新建用于维护集群的hadoop用户" class="headerlink" title="2.5 新建用于维护集群的hadoop用户"></a>2.5 新建用于维护集群的hadoop用户</h3><p>在每台机器上用root用户执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 新建hadoop组</span><br>groupadd hadoop<br><span class="hljs-comment"># 新建hadoop用户</span><br>useradd -s /bin/bash -g hadoop -d /home/hadoop -m hadoop<br><span class="hljs-comment"># 修改 hadoop 这个用户的密码</span><br>passwd hadoop<br></code></pre></td></tr></table></figure>

<h3 id="2-6-生成SSH密钥并分发"><a href="#2-6-生成SSH密钥并分发" class="headerlink" title="2.6 生成SSH密钥并分发"></a>2.6 生成SSH密钥并分发</h3><p>首先在cluster1上切换到<strong>hadoop用户</strong>, 然后执行如下命令生成密钥:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh-keygen -t rsa<br></code></pre></td></tr></table></figure>

<p>随后分发密钥,</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh-copy-id cluster1<br>ssh-copy-id cluster2<br>ssh-copy-id cluster3<br></code></pre></td></tr></table></figure>

<p>密钥分发完毕, 使用cluster1与cluster2和cluster3建立连接均能成功,说明密钥分发无误.</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220308231119122.png"></p>
<h3 id="2-7-安装NTP服务"><a href="#2-7-安装NTP服务" class="headerlink" title="2.7 安装NTP服务"></a>2.7 安装NTP服务</h3><p>在三台机器上安装ntpdate</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">yum install ntpdate<br></code></pre></td></tr></table></figure>

<p>在cluster1上执行yum安装命令安装ntp并将<code>/etc/ntp.conf</code>文件的下列四行注释掉,</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus">server0<span class="hljs-selector-class">.centos</span><span class="hljs-selector-class">.pool</span><span class="hljs-selector-class">.ntp</span><span class="hljs-selector-class">.org</span> iburst<br>server1<span class="hljs-selector-class">.centos</span><span class="hljs-selector-class">.pool</span><span class="hljs-selector-class">.ntp</span><span class="hljs-selector-class">.org</span> iburst <br>server2<span class="hljs-selector-class">.centos</span><span class="hljs-selector-class">.pool</span><span class="hljs-selector-class">.ntp</span><span class="hljs-selector-class">.org</span> iburst <br>server3<span class="hljs-selector-class">.centos</span><span class="hljs-selector-class">.pool</span><span class="hljs-selector-class">.ntp</span><span class="hljs-selector-class">.org</span> iburst<br></code></pre></td></tr></table></figure>

<p>在文件末加入如下内容:</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">restrict</span> default ignore<br>restrict <span class="hljs-number">10.0.2.0</span> mask <span class="hljs-number">255.255.255.0</span> nomodify notrap<br>server <span class="hljs-number">127.127.1.0</span><br></code></pre></td></tr></table></figure>

<p>重启ntp服务并设置ntp 服务器开机自启</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">service</span> ntpd restart<br>chkconfig ntpd <span class="hljs-literal">on</span><br></code></pre></td></tr></table></figure>

<p>接下来对cluster2和cluster3这两个客户端进行配置:</p>
<p>设定每天0:00向服务器同步时间并写入日志:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># crontab -e</span><br></code></pre></td></tr></table></figure>

<p>输入以下内容后保存并退出：</p>
<figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">0 </span><span class="hljs-number">0</span> * * * /<span class="hljs-keyword">usr</span>/sbin/ntpdate cluster1&gt;&gt; /root/ntpd.<span class="hljs-keyword">log</span><br></code></pre></td></tr></table></figure>

<p>之后在两台客户机上使用<code>ntpdate cluster1</code>同步时间.</p>
<h2 id="3-安装MySQL"><a href="#3-安装MySQL" class="headerlink" title="3. 安装MySQL"></a><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309011624607.png">3. 安装MySQL</h2><h3 id="3-1-安装"><a href="#3-1-安装" class="headerlink" title="3.1 安装"></a>3.1 安装</h3><p>只需要在cluster2上安装一个MySQL即可</p>
<p>登录root用户以执行以下命令:</p>
<p>若安装过MySQL先移除原有MySQL:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">yum remove mysql mysql-server mnysql-libs compat-mysql51<br><span class="hljs-built_in">rm</span> -rf /var/lib/mysql<br><span class="hljs-built_in">rm</span> -rf /etc/my.cnf<br></code></pre></td></tr></table></figure>

<p>将mysql-5.6.37-linux-glibc2.12-x86_64.tar.gz上传至cluster2,随后将其解压到/usr/local/目录下,并将解压后的文件目录名改为mysql</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">tar -zxvf mysql-5.6.37-linux-glibc2.12-x86_64.tar.gz<br><span class="hljs-built_in">mv</span> mysql-5.6.37-linux-glibc2.12-x86_64 mysql<br></code></pre></td></tr></table></figure>

<p>将MySQL添加进环境变量:在/etc/profile末尾添加:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> MYSQL_HOME=/usr/local/mysql <br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$MYSQL_HOME</span>/bin:<span class="hljs-variable">$PATH</span><br></code></pre></td></tr></table></figure>

<p>随后用source命令使其生效</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">source</span> /etc/profile<br></code></pre></td></tr></table></figure>

<p>新建MySQL用户:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">groupadd mysql<br>useradd -r -g mysql -s /bin/false mysql<br><span class="hljs-built_in">cd</span> /usr/local/mysql<br><span class="hljs-built_in">chown</span> -R mysql:mysql .<br>scripts/mysql_install_db --user=mysql<br></code></pre></td></tr></table></figure>

<p>将当前目录的拥有者改为root</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">chown</span> -R root<br></code></pre></td></tr></table></figure>

<p>修改当前data目录拥有者为mysql</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">chown</span> -R mysql data<br>bin/mysqld_safe --user=mysql &amp;<br></code></pre></td></tr></table></figure>

<p>用<code>bin/mysql</code>命令登录MySQL,成功后使用<code>exit;</code>命令退出即可</p>
<p>进行修改MySQL的root账户密码操作</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">bin/mysql_secure_installation<br><span class="hljs-built_in">cp</span> support-files/mysql.server /etc/init.d/mysql.server<br></code></pre></td></tr></table></figure>

<p>查看MySQL的进程号并kill掉</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ps -ef | grep mysql<br></code></pre></td></tr></table></figure>

<p>用普通用户配置访问权限:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">mysql -u root -p<br></code></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">GRANT</span> <span class="hljs-keyword">ALL</span> PRIVILEGES <span class="hljs-keyword">ON</span> <span class="hljs-operator">*</span>.<span class="hljs-operator">*</span> <span class="hljs-keyword">TO</span> <span class="hljs-string">&#x27;root&#x27;</span>@<span class="hljs-string">&#x27;%&#x27;</span> IDENTIFIED <span class="hljs-keyword">BY</span> <span class="hljs-string">&#x27;cluster&#x27;</span> <span class="hljs-keyword">WITH</span> <span class="hljs-keyword">GRANT</span> OPTION; <br>mysql<span class="hljs-operator">&gt;</span> FLUSH PRIVILEGES;<br></code></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309193809638.png"></p>
<h3 id="3-2-测试"><a href="#3-2-测试" class="headerlink" title="3.2 测试"></a>3.2 测试</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">create</span> database test_table; <br>mysql<span class="hljs-operator">&gt;</span> use test_table;<br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> userinfo(id <span class="hljs-type">int</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>); <br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">insert</span> <span class="hljs-keyword">into</span> userinfo <span class="hljs-keyword">values</span>(<span class="hljs-number">1</span>); <br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> userinfo;<br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">drop</span> database test_table;<br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">show</span> databases;<br></code></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309194232911.png"></p>
<h2 id="4-安装JDK"><a href="#4-安装JDK" class="headerlink" title="4. 安装JDK"></a>4. 安装JDK</h2><p>需要在每台机器上安装JDK,将jdk压缩包传到服务器<code>/usr/local</code>目录下并解压,修改环境变量:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> JAVA_HOME=/usr/local/jdk1.8.0_102<br><span class="hljs-built_in">export</span> JRE_HOME=/usr/local/jdk1.8.0_102/jre<br><span class="hljs-built_in">export</span> CLASSPATH=.:<span class="hljs-variable">$JAVA_HOME</span>/lib:<span class="hljs-variable">$JRE_HOME</span>/lib:<span class="hljs-variable">$CLASSPATH</span> <br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$JAVA_HOME</span>/bin:<span class="hljs-variable">$JRE_HOME</span>/bin:<span class="hljs-variable">$JAVA_HOME</span>:<span class="hljs-variable">$PATH</span><br></code></pre></td></tr></table></figure>

<p>配置完成,并使用scp命令将jdk复制到其他节点:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309205340946.png"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">scp -r /usr/local/jdk1.7.0_80/ cluster2:/usr/local/<br></code></pre></td></tr></table></figure>

<p>同样的方式将jdk目录写入环境变量</p>
<h2 id="5-安装Zookeeper"><a href="#5-安装Zookeeper" class="headerlink" title="5. 安装Zookeeper"></a>5. 安装Zookeeper</h2><p>最终需要在每一台机器上安装ZooKeeper:</p>
<p>在cluster1上将zookeeper的压缩包解压到/usr/local目录下,</p>
<p>并写入环境变量:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> ZOOKEEPER_HOME=/usr/local/zookeeper-3.4.6 <br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$ZOOKEEPER_HOME</span>/bin:<span class="hljs-variable">$PATH</span><br></code></pre></td></tr></table></figure>

<p>随后在 /usr/local/zookeeper-3.4.6/conf/zoo.cfg中新建zoo.cfg文件,写入如下内容:</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># 客户端心跳时间(毫秒)    </span><br><span class="hljs-attr">tickTime</span>=<span class="hljs-number">2000</span><br><span class="hljs-comment"># 允许心跳间隔的最大时间</span><br><span class="hljs-attr">initLimit</span>=<span class="hljs-number">10</span> <br><span class="hljs-comment"># 同步时限</span><br><span class="hljs-attr">syncLimit</span>=<span class="hljs-number">5</span><br><span class="hljs-comment"># 数据存储目录</span><br><span class="hljs-attr">dataDir</span>=/home/hadoop_files/hadoop_data/zookeeper<br><span class="hljs-comment"># 数据日志存储目录</span><br><span class="hljs-attr">dataLogDir</span>=/home/hadoop_files/hadoop_logs/zookeeper/dataLog <br><span class="hljs-comment"># 端口号</span><br><span class="hljs-attr">clientPort</span>=<span class="hljs-number">2181</span><br><span class="hljs-comment"># 集群节点和服务端口配置</span><br><span class="hljs-attr">server.1</span>=cluster1:<span class="hljs-number">2888</span>:<span class="hljs-number">3888</span> <br><span class="hljs-attr">server.2</span>=cluster2:<span class="hljs-number">2888</span>:<span class="hljs-number">3888</span> <br><span class="hljs-attr">server.3</span>=cluster3:<span class="hljs-number">2888</span>:<span class="hljs-number">3888</span><br></code></pre></td></tr></table></figure>

<p>接下来创建zookeeper的数据目录和日志存储目录, 并修改文件夹的权限:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> -p /home/hadoop_files/hadoop_data/zookeeper<br><span class="hljs-built_in">mkdir</span> -p /home/hadoop_files/hadoop_logs/zookeeper/dataLog <br><span class="hljs-built_in">mkdir</span> -p /home/hadoop_files/hadoop_logs/zookeeper/logs<br><br><span class="hljs-built_in">chown</span> -R hadoop:hadoop /home/hadoop_files<br><span class="hljs-built_in">chown</span> -R hadoop:hadoop /usr/local/zookeeper-3.4.6<br></code></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309214332045.png"></p>
<p>在 cluster1 号服务器的 data 目录中创建一个文件 myid，输入内容为 1, 且myid 应与 zoo.cfg 中的集群节点相匹配, cluster2和cluster3就写2和3</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;1&quot;</span> &gt;&gt; /home/hadoop_files/hadoop_data/zookeeper/myid<br></code></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309214553265.png"></p>
<p>接下来修改zookeeper/目录下相关配置文件</p>
<p>修改 zookeeper 的日志输出路径(注意CDH 版与原生版配置文件不同)</p>
<blockquote>
<p>修改bin/zkEnv.sh中的部分如下所示:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-keyword">if</span> [ <span class="hljs-string">&quot;x<span class="hljs-variable">$&#123;ZOO_LOG_DIR&#125;</span>&quot;</span> = <span class="hljs-string">&quot;x&quot;</span> ]<br><span class="hljs-keyword">then</span><br>ZOO_LOG_DIR=<span class="hljs-string">&quot;/home/hadoop_files/hadoop_logs/zookeeper/logs&quot;</span><br><span class="hljs-keyword">fi</span><br><span class="hljs-keyword">if</span> [ <span class="hljs-string">&quot;x<span class="hljs-variable">$&#123;ZOO_LOG4J_PROP&#125;</span>&quot;</span> = <span class="hljs-string">&quot;x&quot;</span> ]<br><span class="hljs-keyword">then</span><br>ZOO_LOG4J_PROP=<span class="hljs-string">&quot;INFO,ROLLINGFILE&quot;</span><br><span class="hljs-keyword">fi</span><br></code></pre></td></tr></table></figure>
</blockquote>
<p>然后修改conf/zookeeper的日志配置文件<code>log4j.properties</code>:</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs properties"><span class="hljs-attr">zookeeper.root.logger</span>=<span class="hljs-string">INFO,ROLLINGFILE log4j.appender.ROLLINGFILE=org.apache.log4j.DailyRollingFileAppender</span><br></code></pre></td></tr></table></figure>

<p>将zookeeper-3.4.6的内容复制到其他两个节点上:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">scp -r /usr/local/zookeeper-3.4.6 cluster2:/usr/local/ <br>scp -r /usr/local/zookeeper-3.4.6 cluster3:/usr/local/<br></code></pre></td></tr></table></figure>

<p>接下来切换到hadoop用户,使用<code>source /etc/profile</code>刷新环境变量,随后启动zookeeper:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">zkServer.sh start<br></code></pre></td></tr></table></figure>

<p>三台机器都把zookeeper启动之后用命令<code>jps</code>查看进程是否启动:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309234544293.png"></p>
<p>可以看到在每台机器上都能看到一个叫<em>QuorumPeerMain</em>的进程,说明启动成功</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309234950820.png"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309235011745.png"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220309235023280.png"></p>
<p>可以看到三台机器中一台是leader,另两台是follower</p>
<p>zookeeper的关闭命令是<code>zkServer.sh stop</code></p>
<h2 id="6-安装Kafka"><a href="#6-安装Kafka" class="headerlink" title="6. 安装Kafka"></a>6. 安装Kafka</h2><h3 id="6-1-安装"><a href="#6-1-安装" class="headerlink" title="6.1 安装"></a>6.1 安装</h3><p>在cluster1上解压kafka到/usr/local</p>
<p>然后添加环境变量:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> KAFKA_HOME=/usr/local/kafka_2.10-0.8.2.1 <br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$KAFKA_HOME</span>/bin:<span class="hljs-variable">$PATH</span><br></code></pre></td></tr></table></figure>

<p>随后修改<code>kafka/config/server.properties</code>文件:</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs properties"><span class="hljs-comment"># 1. 将brokers 的 id设为唯一的值,这里就把编号作为它的值, 即1,2,3</span><br><span class="hljs-attr">broker.id</span>=<span class="hljs-string">1</span><br><span class="hljs-comment"># 2. 修改日志路径</span><br><span class="hljs-attr">log.dirs</span>=<span class="hljs-string">/home/hadoop_files/hadoop_logs/kafka</span><br><span class="hljs-comment"># 3. zookeeper集群的ip和端口, 用逗号隔开</span><br><span class="hljs-attr">zookeeper.connect</span>=<span class="hljs-string">cluster1:2181,cluster2:2181,cluster3:2181</span><br><span class="hljs-comment"># 4. 对应机器的ip地址!</span><br><span class="hljs-attr">advertised.host.name</span>=<span class="hljs-string">192.168.56.121</span><br></code></pre></td></tr></table></figure>

<p>创建logs文件夹:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> -p /home/hadoop_files/hadoop_logs/kafka<br><span class="hljs-built_in">chown</span> -R hadoop:hadoop /home/hadoop_files<br><span class="hljs-built_in">chown</span> -R hadoop:hadoop /usr/local/kafka_2.10-0.8.2.1<br></code></pre></td></tr></table></figure>

<p>之后使用 hadoop 用户启动 kafka 集群<br>先启动 zookeeper 集群，然后在 kafka 集群中的每个节点使用,下面是启动命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kafka-server-start.sh /usr/local/kafka_2.10-0.8.2.1/config/server.properties &amp;<br></code></pre></td></tr></table></figure>

<h3 id="6-2-测试"><a href="#6-2-测试" class="headerlink" title="6.2 测试"></a>6.2 测试</h3><p>使用hadoop用户执行命令,</p>
<p>创建topic</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kafka-topics.sh --create --zookeeper cluster1:2181,cluster2:2181,cluster3:2181 --replication-factor 3 --partitions 1 --topic mykafka<br></code></pre></td></tr></table></figure>

<p>查看Topic</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kafka-topics.sh --list --zookeeper cluster1:2181,cluster2:2181,cluster3:2181<br></code></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310002701290.png"></p>
<p>查看详细信息:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kafka-topics.sh --describe --zookeeper cluster1:2181,cluster2:2181,cluster3:2181 <br></code></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310002812404.png"></p>
<p>在cluster1上执行如下命令用来发送消息:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kafka-console-producer.sh --broker-list localhost:9092 --topic mykafka<br></code></pre></td></tr></table></figure>

<p>在cluster2上执行如下命令用来接收消息:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kafka-console-consumer.sh -zookeeper cluster1:2181,cluster2:2181,cluster3:2181 --topic mykafka --from-beginning<br></code></pre></td></tr></table></figure>

<p>接着在cluster1上输入以下内容:</p>
<blockquote>
<p>test</p>
<p>mycluster test</p>
</blockquote>
<p>在cluster2上可以成功接收到相应信息</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310003237619.png"></p>
<p>在每台机器上执行<code>kafka-server-stop.sh</code>命令关闭kafka,随后在每台机器上用screen命令新建窗口在后台跑kafka集群</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">screen -S kafka<br>kafka-server-start.sh <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/kafka_2.10-0.8.2.1/</span>config/server.properties<br></code></pre></td></tr></table></figure>

<p>随后使用Ctrl +  A + D退出新建的screen,用<code>jps</code>命令看到Kafka进程在运行</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310003857453.png"></p>
<h2 id="7-安装Hadoop"><a href="#7-安装Hadoop" class="headerlink" title="7. 安装Hadoop"></a>7. 安装Hadoop</h2><h3 id="7-1-安装"><a href="#7-1-安装" class="headerlink" title="7.1 安装"></a>7.1 安装</h3><p><strong>在启动Hadoop之前应先启动zookeeper</strong></p>
<p>以下命令若无特殊说明,均使用 用户hadoop执行</p>
<p>将 hadoop-2.6.5.tar.gz 解压到 /usr/local/ 目录下</p>
<p>进入hadoop配置文件目录:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /usr/local/hadoop-2.6.5/etc/hadoop<br></code></pre></td></tr></table></figure>

<p>修改hadoop-env.sh文件:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> JAVA_HOME=/usr/local/jdk1.7.0_80<br><span class="hljs-built_in">export</span> HADOOP_PID_DIR=/home/hadoop_files<br></code></pre></td></tr></table></figure>

<p>配置mapred-env.sh</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> HADOOP_MAPRED_PID_DIR=/home/hadoop_files<br></code></pre></td></tr></table></figure>

<p>配置core-site.xml文件</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span> <br>    <span class="hljs-comment">&lt;!-- 指定 hdfs的 nameservices名称为 mycluster，与 hdfs-site.xml的 HA配置相同 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://cluster1:9000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span> <br>    <span class="hljs-comment">&lt;!-- 指定缓存文件存储的路径 --&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/home/hadoop_files/hadoop_tmp/hadoop/data/tmp<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 配置 hdfs文件被永久删除前保留的时间（单位：分钟），默认值为 0表明垃圾回收站功能关闭 --&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.trash.interval<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1440<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span> <br>    <span class="hljs-comment">&lt;!-- 指定 zookeeper地址，配置 HA时需要 --&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>ha.zookeeper.quorum<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>cluster1:2181,cluster2:2181,cluster3:2181<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>

<p>配置hdfs-site.xml文件</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span> <br>    <span class="hljs-comment">&lt;!-- 指定 hdfs元数据存储的路径 --&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.name.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/home/hadoop_files/hadoop_data/hadoop/namenode<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 指定 hdfs数据存储的路径 --&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.datanode.data.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/home/hadoop_files/hadoop_data/hadoop/datanode<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.secondary.http.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>cluster1:50090<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span> <br>    <span class="hljs-comment">&lt;!-- 数据备份的个数 --&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>3<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 关闭权限验证 --&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.permissions.enabled<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 开启 WebHDFS功能（基于 REST的接口服务） --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>

<p>配置mapred-site.xml文件</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span> <br>    <span class="hljs-comment">&lt;!-- 指定 MapReduce计算框架使用 YARN --&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 指定 jobhistory server的 rpc地址 --&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>cluster1:10020<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 指定 jobhistory server的 http地址 --&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>cluster1:19888<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span> <br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>

<p>配置yarn-site.xml文件</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span> <br>    <span class="hljs-comment">&lt;!-- NodeManager上运行的附属服务，需配置成 mapreduce_shuffle才可运行 MapReduce程序 --&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 配置 Web Application Proxy安全代理（防止 yarn被攻击） --&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.web-proxy.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>cluster2:8888<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span> <br>    <span class="hljs-comment">&lt;!-- 开启日志 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 配置日志删除时间为 7天， ，-1为禁用，单位为秒 --&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>604800<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 修改日志目录 --&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.remote-app-log-dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/home/hadoop_files/hadoop_logs/yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>cluster1:8032<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>cluster1:8030<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>cluster1:8031<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>

<p>配置slaves文件</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">cluster1</span><br>cluster2 <br>cluster3<br></code></pre></td></tr></table></figure>

<p>在所有节点上创建如下目录,即上述配置涉及的目录:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> -p /home/hadoop_files/hadoop_data/hadoop/namenode <br><span class="hljs-built_in">mkdir</span> -p /home/hadoop_files/hadoop_data/hadoop/datanode<br><span class="hljs-built_in">mkdir</span> -p /home/hadoop_files/hadoop_tmp/hadoop/data/tmp<br><span class="hljs-built_in">mkdir</span> -p /home/hadoop_files/hadoop_logs/yarn<br></code></pre></td></tr></table></figure>

<p>将cluster1的hadoop工作目录同步到集群其他节点:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">scp -r /usr/local/hadoop-2.6.5 cluster2:/usr/local/<br>scp -r /usr/local/hadoop-2.6.5 cluster3:/usr/local/<br></code></pre></td></tr></table></figure>

<p>之后保证工作目录所有者为hadoop用户</p>
<p>每台机器新建环境变量如下, 并使之生效:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> HADOOP_HOME=/usr/local/hadoop-2.6.5<br><span class="hljs-built_in">export</span> LD_LIBRARY_PATH=<span class="hljs-variable">$HADOOP_HOME</span>/lib/native<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$HADOOP_HOME</span>/bin:<span class="hljs-variable">$HADOOP_HOME</span>/sbin:<span class="hljs-variable">$PATH</span><br></code></pre></td></tr></table></figure>

<p>启动zookeeper集群后开始格式化:</p>
<p>在所有节点上启动journalnode</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hadoop-daemon.sh start journalnode<br></code></pre></td></tr></table></figure>

<p>使用jps可以看到journalnode进程</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310010351641.png"></p>
<p>在cluster1上执行格式化HDFS命令:<code>hdfs namenode -format, </code></p>
<p>之后使用<code>hadoop-daemon.sh stop journalnode</code>命令可在节点上关闭journalnode, </p>
<p>在cluster1上启用HDFS:<code>start-dfs.sh</code>, </p>
<p>可在cluster1上看到NameNode, DataNode, SecondaryNameNode;</p>
<p> 在cluster2和cluster3上看到DataNode:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310012508472.png"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310012522550.png"></p>
<p>在cluster1上启用YARN:<code>start-yarn.sh</code></p>
<p>启动后 cluster1 上使用 jps 可以看到NodeManager, ResourceManager, </p>
<p>cluster2 和 cluster3 上可以看到NodeManager:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310012949160.png"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310013004848.png"></p>
<h3 id="7-2-测试"><a href="#7-2-测试" class="headerlink" title="7.2 测试"></a>7.2 测试</h3><p>启动HDFS 后，可以在浏览器中，打开 <a target="_blank" rel="noopener" href="http://192.168.56.121:50070/">http://192.168.56.121:50070</a>，可以看到HDFS 的 web 界面:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310013155182.png"></p>
<p>上图第一页是当前HDFS 的概况，里面显示了HDFS 的启动时间，版本等信息。</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310013244551.png"></p>
<p>Datanodes页面显示了当前HDFS 中的可用节点。</p>
<p>启用YARN后可以通过访问<a target="_blank" rel="noopener" href="http://192.168.56.121:8088/">http://192.168.56.121:8088</a>查看YARN的web界面</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310013421172.png"></p>
<p>该页面展示了所有提交到 YARN 上的程序，点击左侧的Nodes 可以看到 YARN 的节点:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310090014904.png" alt="image-20220310090014904"></p>
<p>此处每个节点的可用内存 Mem Avail 为 8G，而我们的虚拟机每台内存只有 1.5G，由于没有在 yarn-site.xml 这个文件中对节点的可用内存进行配置出现了此问题，可以增加以下内容进行配置：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-comment">&lt;!-- 配置 nodemanager 可用的资源内存 --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>20480<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br><span class="hljs-comment">&lt;!-- 配置 nodemanager 可用的资源 CPU --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>24<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure>



<p>进行命令行测试:</p>
<p>在cluster1上,</p>
<p>首先切换到hadoop用户目录:<code>cd ~/</code></p>
<p>新建一个测试文件:<code>Vi testfile</code></p>
<p>输入:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs">1<br>2<br>3<br></code></pre></td></tr></table></figure>

<p>保存之后退出</p>
<p>在 HDFS 的根目录创建 test 目录: <code>hdfs dfs -mkdir /test</code></p>
<p>查看HDFS 根目录的文件: <code>hdfs dfs -ls /</code></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310014227354.png"></p>
<p>将测试文件 testfile 上传至 HDFS 根目录下的 test 目录中: <code>hdfs dfs -put testfile /test</code></p>
<p>在cluster2上,</p>
<p>首先切换到hadoop用户目录:<code>cd ~/</code></p>
<p>查看HDFS 根目录: <code>hdfs dfs -ls /</code></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310014513363.png"></p>
<p>查看HDFS 根目录下的 test 目录，看到刚才在 cluster1 上上传的文件 testfile: <code>hdfs dfs -ls /test</code></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310014603118.png"></p>
<p>使用<code>hdfs dfs -get /test/testfile</code>将testfile下载到本地,</p>
<p>再查看当前目录下的文件可以发现testfile,</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310014808596.png" alt="image-20220310014808596"></p>
<h2 id="8-安装HBase"><a href="#8-安装HBase" class="headerlink" title="8. 安装HBase"></a>8. 安装HBase</h2><h3 id="8-1-安装"><a href="#8-1-安装" class="headerlink" title="8.1 安装"></a>8.1 安装</h3><p><strong>HBase 启动的先决条件是 zookeeper 和Hadoop 已经启动</strong></p>
<p>在cluster1上, 将hbase-1.2.6-bin.tar.gz解压到/usr/local/目录下,随后修改<code>/usr/local/hbase-1.2.6/conf/</code>目录下的hbase-env.sh如下:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 配置 JDK 安装路径</span><br><span class="hljs-built_in">export</span> JAVA_HOME=/usr/local/jdk1.7.0_80 <br><span class="hljs-comment"># 配置 Hadoop 安装路径</span><br><span class="hljs-built_in">export</span> HADOOP_HOME=/usr/local/hadoop-2.6.5 <br><span class="hljs-comment"># 设置 HBase 的日志目录</span><br><span class="hljs-built_in">export</span> HBASE_LOG_DIR=/home/hadoop_files/hadoop_logs/hbase/logs <br><span class="hljs-comment"># 使用独立的ZooKeeper 集群</span><br><span class="hljs-built_in">export</span> HBASE_MANAGES_ZK=<span class="hljs-literal">false</span> <br><span class="hljs-comment"># 设置 pid 的路径</span><br><span class="hljs-built_in">export</span> HBASE_PID_DIR=/home/hadoop_files<br></code></pre></td></tr></table></figure>

<p>配置hbase-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.rootdir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://cluster1:9000/hbase<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.cluster.distributed<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.master<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>60000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>		    <br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/home/hadoop_files/hadoop_tmp/hbase/tmp<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>cluster1,cluster2,cluster3<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br> 	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/home/hadoop_files/hadoop_data/zookeeper<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br> 	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.zookeeper.property.clientPort<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>2181<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>zookeeper.session.timeout<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>120000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.regionserver.restart.on.zk.expire<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.master.info.port<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>60010<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>

<p>配置regionservers</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">cluster1</span><br>cluster2<br>cluster3<br></code></pre></td></tr></table></figure>

<p>删除hbase的slf4j-log4j12-1.7.5.jar, 解决hbase和hadoop的LSF4J冲突,</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mv</span> /usr/local/hbase-1.2.6/lib/slf4j-log4j12-1.7.5.jar /usr/local/hbase-1.2.6/lib/slf4j-log4j12-1.7.5.jar.bk<br></code></pre></td></tr></table></figure>

<p>将 hbase 工作目录同步到集群其它节点</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">scp -r /usr/local/hbase-1.2.6/ cluster2:/usr/local/ <br>scp -r /usr/local/hbase-1.2.6/ cluster3:/usr/local/<br></code></pre></td></tr></table></figure>

<p>在所有节点创建 hbase 的缓存文件目录和日志文件目录,并修改相应权限</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> -p /home/hadoop_files/hadoop_tmp/hbase/tmp<br><span class="hljs-built_in">mkdir</span> -p /home/hadoop_files/hadoop_logs/hbase/logs<br><span class="hljs-built_in">chown</span> -R hadoop:hadoop /usr/local/hbase-1.2.6 <br><span class="hljs-built_in">chown</span> -R hadoop:hadoop /home/hadoop_files<br></code></pre></td></tr></table></figure>

<p>Hbase的环境变量如下:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> HBASE_HOME=/usr/local/hbase-1.2.6 <br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$HBASE_HOME</span>/bin:<span class="hljs-variable">$PATH</span><br></code></pre></td></tr></table></figure>

<p>在cluster1上,先启动zookeeper, Hadoop的HDFS和YARN,然后才能启动HBase,</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">start-dfs.sh<br>start-yarn.sh<br>start-hbase.sh<br></code></pre></td></tr></table></figure>

<p>启动后在cluster1上使用<code>jps</code>可以看到HMaster和HRegionServer,</p>
<p>cluster2和cluster3上可以看到HRegionServer</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310085135752.png" alt="image-20220310085135752"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310085202547.png" alt="image-20220310085202547"></p>
<h3 id="8-2-测试"><a href="#8-2-测试" class="headerlink" title="8.2 测试"></a>8.2 测试</h3><p>打开<a target="_blank" rel="noopener" href="http://192.168.56.121:60010/">http://192.168.56.121:60010</a>查看Hbase的web界面</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310090107851.png"></p>
<p>在cluster1上, 输入<code>hbase shell</code> 进入hbase shell.键入以下命令:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">hbase&gt; </span><span class="language-bash">create <span class="hljs-string">&#x27;userinfotable&#x27;</span>,&#123;NAME=&gt;<span class="hljs-string">&#x27;username&#x27;</span>&#125;,&#123;NAME=&gt;<span class="hljs-string">&#x27;fullname&#x27;</span>&#125;,&#123;NAME=&gt;<span class="hljs-string">&#x27;homedir&#x27;</span>&#125;</span> <br><span class="hljs-meta prompt_">hbase&gt; </span><span class="language-bash">put <span class="hljs-string">&#x27;userinfotable&#x27;</span>,<span class="hljs-string">&#x27;r1&#x27;</span>,<span class="hljs-string">&#x27;username&#x27;</span>,<span class="hljs-string">&#x27;vcsa&#x27;</span></span><br><span class="hljs-meta prompt_">hbase&gt; </span><span class="language-bash">put <span class="hljs-string">&#x27;userinfotable&#x27;</span>,<span class="hljs-string">&#x27;r2&#x27;</span>,<span class="hljs-string">&#x27;username&#x27;</span>,<span class="hljs-string">&#x27;sasuser&#x27;</span></span> <br><span class="hljs-meta prompt_">hbase&gt; </span><span class="language-bash">scan <span class="hljs-string">&#x27;userinfotable&#x27;</span></span><br></code></pre></td></tr></table></figure>

<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310091241471.png" alt="image-20220310091241471"></p>
<p>在 web 界面也可以看到刚才建立的表:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310091504388.png" alt="image-20220310091504388"></p>
<p>删除刚才建立的表：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">hbase&gt; </span><span class="language-bash"><span class="hljs-built_in">disable</span> <span class="hljs-string">&#x27;userinfotable&#x27;</span></span> <br><span class="hljs-meta prompt_">hbase&gt; </span><span class="language-bash">drop <span class="hljs-string">&#x27;userinfotable&#x27;</span></span> <br><span class="hljs-meta prompt_">hbase&gt; </span><span class="language-bash"><span class="hljs-built_in">exit</span></span><br></code></pre></td></tr></table></figure>

<h2 id="9-安装Hive"><a href="#9-安装Hive" class="headerlink" title="9. 安装Hive"></a>9. 安装Hive</h2><h3 id="9-1-安装"><a href="#9-1-安装" class="headerlink" title="9.1 安装"></a>9.1 安装</h3><p><strong>hive 能启动的先决条件是 MySQL 已经安装并配置完成，而且 HDFS 也要启动之后才能运行 hive</strong></p>
<p>将apache-hive-1.1.0-bin.tar.gz上传到<code>/usr/local</code>并解压</p>
<p>添加环境变量:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> HIVE_HOME=/usr/local/apache-hive-1.1.0-bin<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$HIVE_HOME</span>/bin:<span class="hljs-variable">$HIVE_HOME</span>/conf:<span class="hljs-variable">$PATH</span><br></code></pre></td></tr></table></figure>

<p>使用root用户登录MySQL:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">mysql -u root -p<br></code></pre></td></tr></table></figure>

<p>创建用户hive, 密码hive:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">GRANT</span> USAGE <span class="hljs-keyword">ON</span> <span class="hljs-operator">*</span>.<span class="hljs-operator">*</span> <span class="hljs-keyword">TO</span> <span class="hljs-string">&#x27;hive&#x27;</span>@<span class="hljs-string">&#x27;%&#x27;</span> IDENTIFIED <span class="hljs-keyword">BY</span> <span class="hljs-string">&#x27;hive&#x27;</span> <span class="hljs-keyword">WITH</span> <span class="hljs-keyword">GRANT</span> OPTION;<br></code></pre></td></tr></table></figure>

<p>创建数据库hive</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">create</span> database hive;<br></code></pre></td></tr></table></figure>

<p>允许任意 ip 以hive 登陆数据库</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">grant</span> <span class="hljs-keyword">all</span> <span class="hljs-keyword">on</span> hive.<span class="hljs-operator">*</span> <span class="hljs-keyword">to</span> hive@<span class="hljs-string">&#x27;%&#x27;</span> identified <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;hive&#x27;</span>; <br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">grant</span> <span class="hljs-keyword">all</span> <span class="hljs-keyword">on</span> hive.<span class="hljs-operator">*</span> <span class="hljs-keyword">to</span> hive@<span class="hljs-string">&#x27;localhost&#x27;</span> identified <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;hive&#x27;</span>; <br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">grant</span> <span class="hljs-keyword">all</span> <span class="hljs-keyword">on</span> hive.<span class="hljs-operator">*</span> <span class="hljs-keyword">to</span> hive@<span class="hljs-string">&#x27;cluster2&#x27;</span> identified <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;hive&#x27;</span>;<br></code></pre></td></tr></table></figure>

<p>刷新权限并退出:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> flush privileges;<br>mysql<span class="hljs-operator">&gt;</span> exit;<br></code></pre></td></tr></table></figure>

<p>验证hive用户是否正确创建:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310093902048.png"></p>
<p>接下来修改hive-site.xml</p>
<p>将提供的hive-site.xml上传到apache-hive-1.1.0-bin/conf/目录下即可</p>
<p>将mysql-connector-java-5.1.43-bin.jar上传至 /usr/local/apache-hive-1.1.0-bin/lib/,</p>
<p>将jline-2.12.jar拷贝到/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">cp /usr/local/apache-hive-1.1.0-bin/lib/jline-2.12.jar /usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/<br></code></pre></td></tr></table></figure>

<p>并将原先存在的jline-0.9.94.jar重命名为jline-0.9.94.jar.bak,</p>
<p>切换到hadoop用户执行:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">mkdir -p /home/hadoop_files/hadoop_tmp/hive/iotmp<br>mkdir -p /home/hadoop_files/hadoop_logs/hive/querylog<br></code></pre></td></tr></table></figure>

<h2 id="10-安装Scala"><a href="#10-安装Scala" class="headerlink" title="10. 安装Scala"></a>10. 安装Scala</h2><p>在cluster1上将scala-2.10.6.tgz解压到/usr/local/目录下,</p>
<p>环境变量为:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> SCALA_HOME=/usr/local/scala-2.10.6<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$SCALA_HOME</span>/bin:<span class="hljs-variable">$PATH</span><br></code></pre></td></tr></table></figure>

<p>刷新环境变量后用<code>scala -version</code>查看Scala版本验证安装:</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310115940338.png"></p>
<p>复制到所有的服务器上</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">scp -r /usr/local/scala-2.10.6 cluster2:/usr/local/ <br>scp -r /usr/local/scala-2.10.6 cluster3:/usr/local/<br></code></pre></td></tr></table></figure>

<p>之后设置环境变量,并且修改文件夹权限:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">chown</span> -R hadoop:hadoop /usr/local/scala-2.10.6<br></code></pre></td></tr></table></figure>

<h2 id="11-安装Spark"><a href="#11-安装Spark" class="headerlink" title="11. 安装Spark"></a>11. 安装Spark</h2><h3 id="11-1-安装"><a href="#11-1-安装" class="headerlink" title="11.1 安装"></a>11.1 安装</h3><p>将spark-1.6.3-bin-hadoop2.6.tgz解压到/usr/local</p>
<p>环境变量为:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> SPARK_HOME=/usr/local/spark-1.6.3-bin-hadoop2.6 <br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$SPARK_HOME</span>/bin:<span class="hljs-variable">$PATH</span><br><span class="hljs-comment"># cluster1作为主节点需要再加一行</span><br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$SPARK_HOME</span>/sbin:<span class="hljs-variable">$PATH</span><br></code></pre></td></tr></table></figure>

<p>在 conf 文件夹里面复制一份 template，改名为 spark-env.sh</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cp</span> conf/spark-env.sh.template conf/spark-env.sh<br></code></pre></td></tr></table></figure>

<p>并在其中添加以下语句:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">export</span> JAVA_HOME=/usr/local/jdk1.7.0_80 <br><span class="hljs-built_in">export</span> SCALA_HOME=/usr/local/scala-2.10.6 <br><span class="hljs-built_in">export</span> SPARK_MASTER_IP=cluster1<br><span class="hljs-built_in">export</span> HADOOP_CONF_DIR=/usr/local/hadoop-2.6.5/etc/hadoop<br><span class="hljs-built_in">export</span> SPARK_DIST_CLASSPATH=$(/usr/local/hadoop-2.6.5/bin/hadoop classpath) <br><span class="hljs-built_in">export</span> SPARK_CLASSPATH=<span class="hljs-variable">$HIVE_HOME</span>/lib/mysql-connector-java-5.1.43-bin.jar <br><span class="hljs-built_in">export</span> SPARK_PID_DIR=/home/hadoop_files<br></code></pre></td></tr></table></figure>

<p>在conf下新建slaves文件,内容为:</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">cluster1</span><br>cluster2<br>cluster3<br></code></pre></td></tr></table></figure>

<p>将 hive 目录下 conf 文件夹中的 hive-site.xml 复制到 spark 的 conf 目录下,</p>
<p>将 hadoop/etc/hadoop 文件中的 hdfs-site.xml 和 core-site.xml 文件复制到 spark 的 conf 目录下,</p>
<p>将 conf 目录下的 spark-defaults.conf.template 复制一份，改名为 spark-default.conf ,并在最下面加上一行:<code>spark.files file:///usr/local/spark-1.6.3-bin-hadoop2.6/conf/hdfs-site.xml,file:///usr/local/spark-1.6.3-binhadoop2.6/conf/core-site.xml</code></p>
<p>复制到所有的服务器上</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">scp -r /usr/local/spark-1.6.3-bin-hadoop2.6 cluster2:/usr/local/ <br>scp -r /usr/local/spark-1.6.3-bin-hadoop2.6 cluster3:/usr/local/<br></code></pre></td></tr></table></figure>

<p>修改 spark 文件夹的权限（每个 spark 结点）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">chown</span> -R hadoop:hadoop /usr/local/spark-1.6.3-bin-hadoop2.6<br></code></pre></td></tr></table></figure>

<p>在cluster1上运行Spark</p>
<p>运行 spark 前需启动 hadoop 的HDFS 和 YARN</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">start-master.sh<br>start-slaves.sh<br></code></pre></td></tr></table></figure>

<blockquote>
<p>关闭 Spark 的命令（cluster1 上）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">stop-slaves.sh<br>stop-master.sh<br></code></pre></td></tr></table></figure>
</blockquote>
<h3 id="11-2-测试"><a href="#11-2-测试" class="headerlink" title="11.2 测试"></a>11.2 测试</h3><p>在 cluster1 上使用 jps 命令可以看到 Master 和 Worker，cluster2 和 3 上可以看到Worker,</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310122903560.png"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310122926901.png"></p>
<p>用浏览器访问 &lt;<a target="_blank" rel="noopener" href="http://192.168.56.121:8080/">http://192.168.56.121:8080</a> &gt;可以看到 Spark 的web 界面，可以看到 3 个worker</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310122837660.png"></p>
<h2 id="12-安装Storm"><a href="#12-安装Storm" class="headerlink" title="12. 安装Storm"></a>12. 安装Storm</h2><p>storm需要Python2.6以上版本</p>
<p>将apache-storm-1.1.1.tar.gz解压到<code>/usr/local/</code>下,</p>
<p>环境变量添加:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> STORM_HOME=/usr/local/apache-storm-1.1.1 <br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$STORM_HOME</span>/bin:<span class="hljs-variable">$PATH</span><br></code></pre></td></tr></table></figure>

<p>改一下权限</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">chown</span> -R hadoop:hadoop apache-storm-1.1.1<br></code></pre></td></tr></table></figure>

<p>更改storm/conf/storm.yaml文件:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">storm.zookeeper.servers :</span><br><span class="hljs-string">-</span>	<span class="hljs-string">“cluster1”</span><br><span class="hljs-string">-</span>	<span class="hljs-string">“cluster2”</span><br><span class="hljs-string">-</span>	<span class="hljs-string">“cluster3”</span><br> <span class="hljs-attr">storm.local.dir :</span> <span class="hljs-string">“/home/hadoop_files/hadoop_tmp/storm/tmp”</span><br></code></pre></td></tr></table></figure>

<p>新建tmp文件夹,改权限:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> -p /home/hadoop_files/hadoop_tmp/storm/tmp <br><span class="hljs-built_in">chown</span> -R hadoop:hadoop /home/hadoop_files<br><span class="hljs-built_in">chown</span> -R hadoop:hadoop /usr/local/apache-storm-1.1.1<br></code></pre></td></tr></table></figure>

<p>在cluster1上新建storm-master的虚拟窗口</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">screen -S storm-master<br>storm nimbus<br></code></pre></td></tr></table></figure>

<p>随后将窗口挂到后台</p>
<p>在cluster2,3上新建storm-supervisor的虚拟窗口</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">screen -S storm-master<br>storm supervisor<br></code></pre></td></tr></table></figure>

<p>随后将窗口挂到后台</p>
<p>在cluster1上新建storm-ui的虚拟窗口</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">screen -S storm-ui<br>storm ui<br></code></pre></td></tr></table></figure>

<p>随后将窗口挂到后台</p>
<p>在cluster1,2,3上新建storm-logviewer的虚拟窗口</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">screen -S storm-logviewer<br>storm logviewer<br></code></pre></td></tr></table></figure>

<p>随后将窗口挂到后台</p>
<p>使用 jps 可以看到以下进程</p>
<p>cluster1：nimbus, core, logviewer</p>
<p>cluster2：Supervisor, logviewer</p>
<p>cluster3：Supervisor, logviewer</p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310130740038.png"></p>
<p><img src="https://zxastaticpages.oss-cn-beijing.aliyuncs.com/BlogPictures/image-20220310130759287.png"></p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/htmllearning.html">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">HTML常见标签</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/mcpe_level_intro.html">
                        <span class="hidden-mobile">MCPE 我的世界基岩版level.dat相关配置</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments">
                
                  
                
                
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'CKXGZXA/GitPageComments');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


  
  <!-- 备案信息 -->
  <div class="beian">
    <span>
      <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
        湘ICP备2021018734号
      </a>
    </span>
    
      
        <span>
          <a
            href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=43052102000188"
            rel="nofollow noopener"
            class="beian-police"
            target="_blank"
          >
            
              <span style="visibility: hidden; width: 0">|</span>
              <img src="/img/police_beian.png" alt="police-icon"/>
            
            <span>湘公网安备 43052102000188号</span>
          </a>
        </span>
      
    
  </div>


  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://www.unpkg.com/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://www.unpkg.com/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://www.unpkg.com/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://www.unpkg.com/bootstrap@4.5.3/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->




  



  <script  src="https://www.unpkg.com/tocbot@4.12.2/dist/tocbot.min.js" ></script>



  <script  src="https://www.unpkg.com/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://www.unpkg.com/anchor-js@4.3.0/anchor.min.js" ></script>



  <script defer src="https://www.unpkg.com/clipboard@2.0.8/dist/clipboard.min.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://www.unpkg.com/typed.js@2.0.11/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    (function () {
      var path = "/local-search.xml";
      $('#local-search-input').on('click', function() {
        searchFunc(path, 'local-search-input', 'local-search-result');
      });
      $('#modalSearch').on('shown.bs.modal', function() {
        $('#local-search-input').focus();
      });
    })()
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://www.unpkg.com/mathjax@3.1.2/es5/tex-svg.js" ></script>

  








  
    <!-- Baidu Analytics -->
    <script defer>
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?01f66cc4caefba46f8cad22b739f765a";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  

  

  

  

  

  





<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
